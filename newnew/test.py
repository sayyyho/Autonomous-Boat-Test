"""
KABOAT ì½˜ ê²€ì¶œ í…ŒìŠ¤íŠ¸
í•™ìŠµëœ ëª¨ë¸ë¡œ ì´ë¯¸ì§€/ë¹„ë””ì˜¤/ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸
"""

from ultralytics import YOLO
import cv2
import numpy as np
from pathlib import Path
import argparse


def test_on_image(model_path: str, image_path: str, conf: float = 0.5, save: bool = True):
    """ì´ë¯¸ì§€ì—ì„œ ì½˜ ê²€ì¶œ"""
    print("\n" + "=" * 60)
    print("ğŸ–¼ï¸  ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"ëª¨ë¸: {model_path}")
    print(f"ì´ë¯¸ì§€: {image_path}")
    print(f"ì‹ ë¢°ë„ ì„ê³„ê°’: {conf}")
    print("=" * 60)
    
    if not Path(image_path).exists():
        print(f"âŒ ì´ë¯¸ì§€ ì—†ìŒ: {image_path}")
        return
    
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(model_path)
    
    # ì¶”ë¡ 
    results = model(image_path, conf=conf)
    
    # ê²°ê³¼ ì²˜ë¦¬
    for r in results:
        img = r.orig_img.copy()
        
        print(f"\nğŸ¯ ê²€ì¶œ ê²°ê³¼:")
        print(f"   ì´ {len(r.boxes)}ê°œ ê²€ì¶œ")
        
        if len(r.boxes) == 0:
            print("   âš ï¸  ì½˜ ê²€ì¶œ ì•ˆ ë¨")
            print(f"   ğŸ’¡ ì‹ ë¢°ë„ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”: --conf 0.3")
        else:
            # ê° ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬
            for i, box in enumerate(r.boxes):
                cls_idx = int(box.cls[0])
                cls_name = r.names[cls_idx]
                confidence = float(box.conf[0])
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                
                print(f"   {i+1}. {cls_name}: {confidence:.3f} at ({x1},{y1})-({x2},{y2})")
                
                # ìƒ‰ìƒ ì„¤ì •
                if cls_name == 'green_cone':
                    color = (0, 255, 0)  # ì´ˆë¡
                elif cls_name == 'red_cone':
                    color = (0, 0, 255)  # ë¹¨ê°•
                else:
                    color = (255, 255, 255)  # í°ìƒ‰
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
                
                # ë¼ë²¨ ë°°ê²½
                label = f'{cls_name} {confidence:.2f}'
                label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
                cv2.rectangle(img, (x1, y1-label_size[1]-10), (x1+label_size[0], y1), color, -1)
                
                # ë¼ë²¨ í…ìŠ¤íŠ¸
                cv2.putText(img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, (255, 255, 255), 2)
        
        # ì €ì¥
        if save:
            output_path = 'cone_detection_result.jpg'
            cv2.imwrite(output_path, img)
            print(f"\nğŸ’¾ ì €ì¥: {output_path}")
        
        # í‘œì‹œ
        cv2.imshow('Cone Detection', img)
        print("\nâŒ¨ï¸  ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œ...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    print("=" * 60)


def test_on_video(model_path: str, video_path: str, conf: float = 0.5, save: bool = False):
    """ë¹„ë””ì˜¤ì—ì„œ ì½˜ ê²€ì¶œ"""
    print("\n" + "=" * 60)
    print("ğŸ¥ ë¹„ë””ì˜¤ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"ëª¨ë¸: {model_path}")
    print(f"ë¹„ë””ì˜¤: {video_path}")
    print(f"ì‹ ë¢°ë„: {conf}")
    print("=" * 60)
    
    if not Path(video_path).exists():
        print(f"âŒ ë¹„ë””ì˜¤ ì—†ìŒ: {video_path}")
        return
    
    model = YOLO(model_path)
    cap = cv2.VideoCapture(video_path)
    
    # ë¹„ë””ì˜¤ ì •ë³´
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"\nğŸ“Š ë¹„ë””ì˜¤ ì •ë³´:")
    print(f"   í•´ìƒë„: {width}x{height}")
    print(f"   FPS: {fps}")
    print(f"   ì´ í”„ë ˆì„: {total_frames}")
    
    # ì €ì¥ ì„¤ì •
    if save:
        output_path = 'cone_detection_video.mp4'
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        print(f"   ì €ì¥: {output_path}")
    
    frame_count = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        
        # ì¶”ë¡ 
        results = model(frame, conf=conf, verbose=False)
        
        for r in results:
            # ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸°
            for box in r.boxes:
                cls_name = r.names[int(box.cls[0])]
                confidence = float(box.conf[0])
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                
                color = (0, 255, 0) if cls_name == 'green_cone' else (0, 0, 255)
                
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                label = f'{cls_name} {confidence:.2f}'
                cv2.putText(frame, label, (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # FPS í‘œì‹œ
        cv2.putText(frame, f'Frame: {frame_count}/{total_frames}', 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        if save:
            out.write(frame)
        
        cv2.imshow('Cone Detection - Video', frame)
        
        # 'q' ëˆ„ë¥´ë©´ ì¢…ë£Œ
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("\nâš ï¸  ì‚¬ìš©ì ì¤‘ë‹¨")
            break
    
    cap.release()
    if save:
        out.release()
        print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    cv2.destroyAllWindows()
    print("=" * 60)


def test_on_webcam(model_path: str, conf: float = 0.5, camera_id: int = 0):
    """ì›¹ìº  ì‹¤ì‹œê°„ ì½˜ ê²€ì¶œ"""
    print("\n" + "=" * 60)
    print("ğŸ“¹ ì›¹ìº  ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"ëª¨ë¸: {model_path}")
    print(f"ì¹´ë©”ë¼ ID: {camera_id}")
    print(f"ì‹ ë¢°ë„: {conf}")
    print("=" * 60)
    print("\nğŸ’¡ ì¡°ì‘ë²•:")
    print("   - 'q': ì¢…ë£Œ")
    print("   - 'c': ìŠ¤í¬ë¦°ìƒ· ì €ì¥")
    print("=" * 60)
    
    model = YOLO(model_path)
    cap = cv2.VideoCapture(camera_id)
    
    if not cap.isOpened():
        print(f"âŒ ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨ (ID: {camera_id})")
        return
    
    frame_count = 0
    screenshot_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
            break
        
        frame_count += 1
        
        # ì¶”ë¡  (ë§¤ í”„ë ˆì„)
        results = model(frame, conf=conf, verbose=False)
        
        green_count = 0
        red_count = 0
        
        for r in results:
            for box in r.boxes:
                cls_idx = int(box.cls[0])
                cls_name = r.names[cls_idx]
                confidence = float(box.conf[0])
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                
                if cls_name == 'green_cone':
                    color = (0, 255, 0)
                    green_count += 1
                else:
                    color = (0, 0, 255)
                    red_count += 1
                
                # ë°”ìš´ë”© ë°•ìŠ¤
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                
                # ë¼ë²¨
                label = f'{cls_name} {confidence:.2f}'
                cv2.putText(frame, label, (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # í†µê³„ í‘œì‹œ
        cv2.putText(frame, f'Green: {green_count}', (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f'Red: {red_count}', (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        cv2.putText(frame, f'Frame: {frame_count}', (10, 110), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        cv2.imshow('Cone Detection - Webcam', frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            print("\nâœ… ì¢…ë£Œ")
            break
        elif key == ord('c'):
            screenshot_count += 1
            filename = f'screenshot_{screenshot_count}.jpg'
            cv2.imwrite(filename, frame)
            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
    
    cap.release()
    cv2.destroyAllWindows()
    print("=" * 60)


def validate_model(model_path: str, data_yaml: str):
    """ëª¨ë¸ ê²€ì¦"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ëª¨ë¸ ê²€ì¦")
    print("=" * 60)
    
    model = YOLO(model_path)
    results = model.val(data=data_yaml, verbose=True)
    
    print(f"\nğŸ“ˆ ì „ì²´ ì„±ëŠ¥:")
    print(f"   mAP50: {results.box.map50:.3f}")
    print(f"   mAP50-95: {results.box.map:.3f}")
    print(f"   Precision: {results.box.p:.3f}")
    print(f"   Recall: {results.box.r:.3f}")
    
    print(f"\nğŸ“Š í´ë˜ìŠ¤ë³„ mAP50:")
    for i, name in enumerate(results.names.values()):
        print(f"   {name}: {results.box.maps[i]:.3f}")
    
    if results.box.map50 >= 0.7:
        print("\n   âœ… ì„±ëŠ¥ ì¢‹ìŒ!")
    elif results.box.map50 >= 0.5:
        print("\n   âš ï¸  ê°œì„  í•„ìš”")
    else:
        print("\n   âŒ ì¬í›ˆë ¨ ê¶Œì¥")
    
    print("=" * 60)


def main():
    parser = argparse.ArgumentParser(description='KABOAT ì½˜ ê²€ì¶œ í…ŒìŠ¤íŠ¸')
    
    parser.add_argument('--weights', type=str, 
                       default='runs/detect/kaboat_cone_only/weights/best.pt',
                       help='ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--mode', type=str, default='image',
                       choices=['image', 'video', 'webcam', 'validate'],
                       help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ')
    parser.add_argument('--source', type=str, default='test.jpg',
                       help='ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ê²½ë¡œ')
    parser.add_argument('--conf', type=float, default=0.5,
                       help='ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0)')
    parser.add_argument('--save', action='store_true',
                       help='ê²°ê³¼ ì €ì¥')
    parser.add_argument('--camera', type=int, default=0,
                       help='ì¹´ë©”ë¼ ID (0, 1, ...)')
    parser.add_argument('--data', type=str, 
                       default='./cone_only/data_cone_only.yaml',
                       help='ê²€ì¦ìš© data.yaml ê²½ë¡œ')
    
    args = parser.parse_args()
    
    print("\n" + "=" * 60)
    print("ğŸš¢ KABOAT ì½˜ ê²€ì¶œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    if args.mode == 'image':
        test_on_image(args.weights, args.source, args.conf, args.save)
    elif args.mode == 'video':
        test_on_video(args.weights, args.source, args.conf, args.save)
    elif args.mode == 'webcam':
        test_on_webcam(args.weights, args.conf, args.camera)
    elif args.mode == 'validate':
        validate_model(args.weights, args.data)


if __name__ == '__main__':
    main()