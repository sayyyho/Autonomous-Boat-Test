#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
KABOAT Phase1: Depth-based Gate Selection (ê¹Šì´ ê¸°ë°˜ ê²Œì´íŠ¸ ì„ íƒ)
- ê°€ì¥ ê°€ê¹Œìš´ ê²Œì´íŠ¸ ìŒ ìš°ì„  ì„ íƒ
- ë©´ì  + Yì¢Œí‘œ ê¸°ë°˜ ê±°ë¦¬ ì¶”ì •
"""

import time
import serial
from typing import List, Tuple, Optional, Dict
import cv2
import numpy as np
from ultralytics import YOLO
from pathlib import Path

# ===========================
# ì„¤ì • íŒŒë¼ë¯¸í„°
# ===========================

SERIAL_PORT = '/dev/ttyACM0'
BAUD_RATE = 9600
DEFAULT_SPEED = '5'

TOTAL_GATES = int(input("í†µê³¼í•  ê²Œì´íŠ¸ ìˆ˜ (ê¸°ë³¸ 5): ") or "5")
print(f"âœ… ì´ {TOTAL_GATES}ê°œì˜ ê²Œì´íŠ¸ë¥¼ í†µê³¼í•©ë‹ˆë‹¤.")

MODEL_PATH = './cone.pt'
CONFIDENCE_THRESHOLD = 0.5

CAMERA_WIDTH = 640
CAMERA_HEIGHT = 480

# â­ ê²Œì´íŠ¸ ì„ íƒ ê¸°ì¤€
Y_ALIGNMENT_THRESHOLD = 100  # ìˆ˜í‰ ì •ë ¬ í—ˆìš© ì˜¤ì°¨ (ë„‰ë„‰í•˜ê²Œ)
MIN_CONE_AREA = 400  # ìµœì†Œ ì½˜ ë©´ì  (ì‘ê²Œ â†’ ì›ê±°ë¦¬ë„ ê°ì§€)
GATE_CENTER_DEADZONE = 50

# â­ ê¹Šì´ ê°€ì¤‘ì¹˜
AREA_WEIGHT = 0.6  # ë©´ì  ë¹„ì¤‘
Y_WEIGHT = 0.4     # Yì¢Œí‘œ ë¹„ì¤‘

# íƒ€ì´ë°
FORWARD_TIME = 0.3
TURN_TIME = 0.4
SCAN_TURN_TIME = 1.2
APPROACH_TIME = 0.6
GATE_PASS_TIME = 2.0

# ===========================
# ì•„ë‘ì´ë…¸ ëª¨í„° ì œì–´
# ===========================

class ArduinoMotorController:
    def __init__(self, port: str = SERIAL_PORT, baudrate: int = BAUD_RATE):
        self.ser = None
        self.use_serial = True
        
        try:
            self.ser = serial.Serial(port, baudrate, timeout=1)
            time.sleep(2)
            self.set_speed(DEFAULT_SPEED)
            self.stop()
            print(f"âœ… ì•„ë‘ì´ë…¸ ì—°ê²°: {port}")
        except Exception as e:
            print(f"âš ï¸  ì•„ë‘ì´ë…¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            print("âš ï¸  ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            self.use_serial = False
    
    def send_command(self, command: bytes):
        if self.use_serial and self.ser and self.ser.is_open:
            self.ser.write(command)
            time.sleep(0.01)
        else:
            cmd = command.decode('utf-8', errors='ignore')
            print(f"[MOTOR] {cmd}")
    
    def set_speed(self, speed: str):
        if speed.isdigit() and '0' <= speed <= '9':
            self.send_command(speed.encode())
    
    def forward(self):
        self.send_command(b'w')
    
    def backward(self):
        self.send_command(b's')
    
    def left(self):
        self.send_command(b'a')
    
    def right(self):
        self.send_command(b'd')
    
    def stop(self):
        self.send_command(b'x')
    
    def close(self):
        if self.use_serial and self.ser and self.ser.is_open:
            self.stop()
            self.ser.close()
            print("âœ… ì•„ë‘ì´ë…¸ ì¢…ë£Œ")


# ===========================
# ì¹´ë©”ë¼ ì´ˆê¸°í™”
# ===========================

def find_camera(max_index=10) -> Optional[cv2.VideoCapture]:
    for i in range(max_index + 1):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            ret, _ = cap.read()
            if ret:
                print(f"âœ… ì¹´ë©”ë¼ ì¸ë±ìŠ¤ {i}ë²ˆ ì‚¬ìš©")
                return cap
            cap.release()
    return None


# ===========================
# YOLO ì½˜ ê²€ì¶œê¸°
# ===========================

class YOLOConeDetector:
    def __init__(self, model_path: str, conf_threshold: float = 0.5):
        self.model_path = Path(model_path)
        self.conf_threshold = conf_threshold
        
        if not self.model_path.exists():
            raise FileNotFoundError(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        
        print(f"ğŸ“¦ YOLO ëª¨ë¸ ë¡œë”©: {model_path}")
        self.model = YOLO(str(model_path))
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì‹ ë¢°ë„: {conf_threshold})")
    
    def detect(self, frame: np.ndarray) -> Tuple[List[Dict], List[Dict]]:
        results = self.model(frame, conf=self.conf_threshold, verbose=False)
        
        red_cones = []
        green_cones = []
        
        for r in results:
            for box in r.boxes:
                cls_idx = int(box.cls[0])
                cls_name = r.names[cls_idx]
                confidence = float(box.conf[0])
                
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                w, h = x2 - x1, y2 - y1
                
                area = w * h
                if area < MIN_CONE_AREA:
                    continue
                
                cx, cy = x1 + w // 2, y1 + h // 2
                
                # â­ í•˜ë‹¨ Yì¢Œí‘œ (ê¹Šì´ ì¶”ì •ìš©)
                bottom_y = y2
                
                cone_data = {
                    'bbox': (x1, y1, w, h),
                    'conf': confidence,
                    'center': (cx, cy),
                    'area': area,
                    'bottom_y': bottom_y  # ì¶”ê°€
                }
                
                if cls_name == 'red_cone':
                    red_cones.append(cone_data)
                elif cls_name == 'green_cone':
                    green_cones.append(cone_data)
        
        return red_cones, green_cones


# ===========================
# â­ ê¹Šì´ ê¸°ë°˜ ê²Œì´íŠ¸ ê²€ì¶œ
# ===========================

def calculate_depth_score(cone: Dict, max_area: float, max_y: float) -> float:
    """
    ê¹Šì´ ì ìˆ˜ ê³„ì‚° (ë†’ì„ìˆ˜ë¡ ê°€ê¹Œì›€)
    
    Args:
        cone: ì½˜ ì •ë³´
        max_area: ì „ì²´ ì½˜ ì¤‘ ìµœëŒ€ ë©´ì 
        max_y: ì „ì²´ ì½˜ ì¤‘ ìµœëŒ€ Yì¢Œí‘œ
    
    Returns:
        0~1 ì‚¬ì´ì˜ ê¹Šì´ ì ìˆ˜
    """
    # ë©´ì  ì •ê·œí™” (0~1)
    area_score = cone['area'] / max_area if max_area > 0 else 0
    
    # Yì¢Œí‘œ ì •ê·œí™” (0~1)
    y_score = cone['bottom_y'] / max_y if max_y > 0 else 0
    
    # ê°€ì¤‘ í•©ì‚°
    depth_score = AREA_WEIGHT * area_score + Y_WEIGHT * y_score
    
    return depth_score


def find_nearest_gate_pair(red_cones: List[Dict], 
                           green_cones: List[Dict],
                           frame_width: int,
                           frame_height: int) -> Optional[Tuple[Dict, Dict, float]]:
    """
    ê°€ì¥ ê°€ê¹Œìš´(depth ì ìˆ˜ ë†’ì€) ê²Œì´íŠ¸ ìŒ ì°¾ê¸°
    
    Returns:
        (red_cone, green_cone, depth_score) or None
    """
    if not red_cones or not green_cones:
        return None
    
    # ì „ì²´ ì½˜ì—ì„œ ìµœëŒ€ê°’ êµ¬í•˜ê¸° (ì •ê·œí™”ìš©)
    all_cones = red_cones + green_cones
    max_area = max(c['area'] for c in all_cones)
    max_y = max(c['bottom_y'] for c in all_cones)
    
    best_gate = None
    best_depth = -1
    
    for green in green_cones:
        green_cx, green_cy = green['center']
        
        for red in red_cones:
            red_cx, red_cy = red['center']
            
            # ì¡°ê±´ 1: ì´ˆë¡(ì™¼ìª½) - ë¹¨ê°•(ì˜¤ë¥¸ìª½) ë°°ì¹˜
            if green_cx >= red_cx:
                continue
            
            # ì¡°ê±´ 2: Yì¢Œí‘œ ìˆ˜í‰ ì •ë ¬
            y_diff = abs(green_cy - red_cy)
            if y_diff > Y_ALIGNMENT_THRESHOLD:
                continue
            
            # â­ ì¡°ê±´ 3: ê²Œì´íŠ¸ ìŒì˜ í‰ê·  ê¹Šì´ ì ìˆ˜ ê³„ì‚°
            green_depth = calculate_depth_score(green, max_area, max_y)
            red_depth = calculate_depth_score(red, max_area, max_y)
            
            # ë‘ ì½˜ì˜ í‰ê·  ê¹Šì´
            avg_depth = (green_depth + red_depth) / 2.0
            
            # ì¶”ê°€ ë³´ë„ˆìŠ¤: í™”ë©´ ì¤‘ì•™ì— ê°€ê¹Œìš°ë©´ ê°€ì‚°ì 
            gate_cx = (green_cx + red_cx) // 2
            center_distance = abs(gate_cx - frame_width // 2)
            center_bonus = 1.0 - (center_distance / frame_width) * 0.2  # ìµœëŒ€ 20% ê°€ì‚°
            
            final_score = avg_depth * center_bonus
            
            if final_score > best_depth:
                best_depth = final_score
                best_gate = (red, green, final_score)
    
    return best_gate


# ===========================
# ë©”ì¸ ë„¤ë¹„ê²Œì´í„°
# ===========================

class DepthBasedNavigator:
    def __init__(self, cap: cv2.VideoCapture, model_path: str):
        self.cap = cap
        self.motor = ArduinoMotorController()
        self.detector = YOLOConeDetector(model_path, CONFIDENCE_THRESHOLD)
        
        self.mission_stage = 'NAVIGATION'
        self.gates_passed = 0
        self.gate_state = 'SEARCHING'
        
        self.last_gate_seen = time.time()
        self.scan_direction = 'right'
        self.last_scan_time = 0
        
        self._t_prev = time.time()
        self._fps_smooth = None
        
        print("=" * 60)
        print("ğŸš¢ Depth-based Navigator ì‹œì‘")
        print("=" * 60)
    
    def _update_fps(self) -> float:
        t = time.time()
        dt = t - self._t_prev
        self._t_prev = t
        fps = 1.0 / dt if dt > 1e-6 else 0.0
        
        if self._fps_smooth is None:
            self._fps_smooth = fps
        else:
            self._fps_smooth = 0.9 * self._fps_smooth + 0.1 * fps
        
        return self._fps_smooth
    
    def visualize_detections(self, frame: np.ndarray, 
                            red_cones: List[Dict], 
                            green_cones: List[Dict],
                            gate_info: Optional[Tuple[Dict, Dict, float]] = None):
        """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
        
        # ì„ íƒëœ ê²Œì´íŠ¸ ìŒ
        selected_red = gate_info[0] if gate_info else None
        selected_green = gate_info[1] if gate_info else None
        
        # ì´ˆë¡ ì½˜
        for cone in green_cones:
            x, y, w, h = cone['bbox']
            conf = cone['conf']
            cx, cy = cone['center']
            area = cone['area']
            
            is_selected = (selected_green and cone == selected_green)
            color = (0, 255, 255) if is_selected else (0, 255, 0)  # ì„ íƒë˜ë©´ ë…¸ë€ìƒ‰
            thickness = 4 if is_selected else 2
            
            cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness)
            cv2.circle(frame, (cx, cy), 5, color, -1)
            
            label = f'G {conf:.2f} A:{area}'
            cv2.putText(frame, label, (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # ë¹¨ê°• ì½˜
        for cone in red_cones:
            x, y, w, h = cone['bbox']
            conf = cone['conf']
            cx, cy = cone['center']
            area = cone['area']
            
            is_selected = (selected_red and cone == selected_red)
            color = (0, 255, 255) if is_selected else (0, 0, 255)
            thickness = 4 if is_selected else 2
            
            cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness)
            cv2.circle(frame, (cx, cy), 5, color, -1)
            
            label = f'R {conf:.2f} A:{area}'
            cv2.putText(frame, label, (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # â­ ì„ íƒëœ ê²Œì´íŠ¸ ê°•ì¡°
        if gate_info:
            red, green, depth_score = gate_info
            red_cx, red_cy = red['center']
            green_cx, green_cy = green['center']
            
            gate_cx = (red_cx + green_cx) // 2
            gate_cy = (red_cy + green_cy) // 2
            
            # ê²Œì´íŠ¸ ì¤‘ì‹¬ì„ 
            cv2.line(frame, (gate_cx, 0), (gate_cx, CAMERA_HEIGHT), 
                    (0, 255, 255), 3)
            
            # ê²Œì´íŠ¸ ì—°ê²°ì„ 
            cv2.line(frame, (green_cx, green_cy), (red_cx, red_cy), 
                    (255, 0, 255), 3)
            
            # ê²Œì´íŠ¸ ì¤‘ì‹¬
            cv2.circle(frame, (gate_cx, gate_cy), 12, (0, 255, 255), -1)
            
            # â­ ê¹Šì´ ì ìˆ˜ í‘œì‹œ
            label = f"GATE #{self.gates_passed+1} | Depth: {depth_score:.2f}"
            cv2.putText(frame, label, (gate_cx-80, gate_cy-25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # í™”ë©´ ì¤‘ì‹¬ì„ 
        cv2.line(frame, (CAMERA_WIDTH//2, 0), 
                (CAMERA_WIDTH//2, CAMERA_HEIGHT), (255, 255, 255), 1)
        
        return frame
    
    def draw_info(self, frame: np.ndarray, 
                  red_count: int, green_count: int):
        cv2.putText(frame, 
                   f"Stage: {self.mission_stage} | Gates: {self.gates_passed}/{TOTAL_GATES}", 
                   (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Green: {green_count} | Red: {red_count}", 
                   (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        cv2.putText(frame, f"State: {self.gate_state}", 
                   (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        fps = self._update_fps()
        cv2.putText(frame, f"{fps:.1f} FPS", 
                   (20, CAMERA_HEIGHT - 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (180, 180, 180), 2)
        
        return frame
    
    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        # YOLO ê²€ì¶œ
        red_cones, green_cones = self.detector.detect(frame)
        
        # â­ ê¹Šì´ ê¸°ë°˜ ê²Œì´íŠ¸ ì°¾ê¸°
        gate_info = find_nearest_gate_pair(red_cones, green_cones, 
                                           CAMERA_WIDTH, CAMERA_HEIGHT)
        
        # ì‹œê°í™”
        frame = self.visualize_detections(frame, red_cones, green_cones, gate_info)
        frame = self.draw_info(frame, len(red_cones), len(green_cones))
        
        # í•­ë²•
        if self.mission_stage == 'NAVIGATION':
            self.navigation_logic(gate_info, frame)
        elif self.mission_stage == 'COMPLETE':
            self.complete_logic(frame)
        
        return frame
    
    def navigation_logic(self, gate_info: Optional[Tuple[Dict, Dict, float]], 
                        frame: np.ndarray):
        if self.gates_passed >= TOTAL_GATES:
            self.mission_stage = 'COMPLETE'
            return
        
        if gate_info:
            self.last_gate_seen = time.time()
            self.approach_and_pass_gate(gate_info, frame)
        else:
            self.search_gate()
    
    def approach_and_pass_gate(self, gate_info: Tuple[Dict, Dict, float], 
                               frame: np.ndarray):
        red, green, depth_score = gate_info
        red_cx, red_cy = red['center']
        green_cx, green_cy = green['center']
        
        gate_cx = (red_cx + green_cx) // 2
        gate_cy = (red_cy + green_cy) // 2
        
        frame_cx = CAMERA_WIDTH // 2
        
        # â­ ê¹Šì´ ì ìˆ˜ ê¸°ë°˜ í†µê³¼ íŒë‹¨ (ì ìˆ˜ ë†’ìœ¼ë©´ â†’ ê°€ê¹Œì›€)
        if depth_score > 0.6 or gate_cy > CAMERA_HEIGHT * 0.65:
            if self.gate_state != 'PASSING':
                self.gate_state = 'PASSING'
                print(f"ğŸšª ê²Œì´íŠ¸ #{self.gates_passed+1} í†µê³¼ (ê¹Šì´: {depth_score:.2f})")
            
            error = gate_cx - frame_cx
            if abs(error) > GATE_CENTER_DEADZONE // 2:
                if error > 0:
                    self.motor.right()
                else:
                    self.motor.left()
                time.sleep(TURN_TIME * 0.3)
            
            self.motor.forward()
            time.sleep(GATE_PASS_TIME)
            self.motor.stop()
            
            self.gates_passed += 1
            print(f"âœ… ê²Œì´íŠ¸ #{self.gates_passed}/{TOTAL_GATES} í†µê³¼!")
            
            self.gate_state = 'SEARCHING'
            time.sleep(0.5)
        
        else:
            self.gate_state = 'APPROACHING'
            error = gate_cx - frame_cx
            
            if abs(error) <= GATE_CENTER_DEADZONE:
                print(f"â†’ ê²Œì´íŠ¸ ì¤‘ì•™ ì •ë ¬ (ê¹Šì´: {depth_score:.2f}) â†’ ì§ì§„")
                self.motor.forward()
                time.sleep(APPROACH_TIME)
            elif error > 0:
                print(f"â†’ ìš°ì¸¡ {error}px (ê¹Šì´: {depth_score:.2f}) â†’ ìš°íšŒì „")
                self.motor.right()
                time.sleep(TURN_TIME * min(abs(error)/100, 1.0))
                self.motor.forward()
                time.sleep(APPROACH_TIME * 0.5)
            else:
                print(f"â†’ ì¢Œì¸¡ {abs(error)}px (ê¹Šì´: {depth_score:.2f}) â†’ ì¢ŒíšŒì „")
                self.motor.left()
                time.sleep(TURN_TIME * min(abs(error)/100, 1.0))
                self.motor.forward()
                time.sleep(APPROACH_TIME * 0.5)
            
            self.motor.stop()
    
    def search_gate(self):
        self.gate_state = 'SEARCHING'
        
        if time.time() - self.last_gate_seen < 2.0:
            self.motor.forward()
            time.sleep(FORWARD_TIME)
            self.motor.stop()
            return
        
        if time.time() - self.last_scan_time >= 2.0:
            self.scan_for_gate()
        else:
            self.motor.stop()
    
    def scan_for_gate(self):
        self.last_scan_time = time.time()
        print(f"ğŸ” [{self.scan_direction}] ìŠ¤ìº”...")
        
        if self.scan_direction == 'left':
            self.motor.left()
            time.sleep(SCAN_TURN_TIME)
            self.scan_direction = 'right'
        else:
            self.motor.right()
            time.sleep(SCAN_TURN_TIME)
            self.scan_direction = 'left'
        
        self.motor.stop()
    
    def complete_logic(self, frame: np.ndarray):
        cv2.putText(frame, "MISSION COMPLETE!", 
                   (150, 240), cv2.FONT_HERSHEY_SIMPLEX, 
                   1.5, (0, 255, 0), 3)
        self.motor.stop()
        print("ğŸ‰ Phase1 ì™„ë£Œ!")
    
    def run(self):
        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                    break
                
                processed = self.process_frame(frame)
                cv2.imshow("Depth-based Gate Navigator", processed)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("\nì‚¬ìš©ì ì¢…ë£Œ")
                    break
                elif key == ord('s'):
                    filename = f"screenshot_{int(time.time())}.jpg"
                    cv2.imwrite(filename, processed)
                    print(f"ğŸ“¸ {filename}")
                
                if self.mission_stage == 'COMPLETE':
                    cv2.waitKey(3000)
                    break
        
        except KeyboardInterrupt:
            print("\nâš ï¸  ì¤‘ë‹¨")
        finally:
            self.cleanup()
    
    def cleanup(self):
        self.motor.close()
        self.cap.release()
        cv2.destroyAllWindows()
        print("âœ… ì¢…ë£Œ")


# ===========================
# ë©”ì¸ ì‹¤í–‰
# ===========================

def main():
    print("\n" + "=" * 60)
    print("ğŸš¢ KABOAT Depth-based Gate Navigator")
    print("=" * 60)
    
    model_path = Path(MODEL_PATH)
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {MODEL_PATH}")
        return
    
    cap = find_camera(10)
    if cap is None:
        print("âŒ ì¹´ë©”ë¼ ì—†ìŒ")
        return
    
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    
    navigator = DepthBasedNavigator(cap, MODEL_PATH)
    navigator.run()


if __name__ == '__main__':
    main()