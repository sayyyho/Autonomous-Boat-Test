"""
KABOAT ì½˜ ê²€ì¶œê¸° í›ˆë ¨
green_cone, red_coneë§Œ ì§‘ì¤‘ í•™ìŠµ
"""

from ultralytics import YOLO
import yaml
import os
from pathlib import Path
import torch
import shutil


def detect_device():
    if torch.cuda.is_available():
        device = '0'
        device_name = f"GPU ({torch.cuda.get_device_name(0)})"
        print(f"âœ… GPU: {device_name}")
    else:
        device = 'cpu'
        device_name = "CPU"
        print(f"âš ï¸  CPU ëª¨ë“œ")
    return device, device_name


def create_cone_only_yaml(original_dataset_path: str, output_path: str = './cone_only'):
    """
    green_cone, red_coneë§Œ í¬í•¨í•˜ëŠ” data.yaml ìƒì„±
    """
    original_path = Path(original_dataset_path)
    output_path = Path(output_path)
    
    print("=" * 60)
    print("ğŸ”§ ì½˜ ì „ìš© ë°ì´í„°ì…‹ ìƒì„±")
    print("=" * 60)
    
    # ì¶œë ¥ í´ë” ìƒì„±
    output_path.mkdir(exist_ok=True)
    
    # ì›ë³¸ data.yaml ì½ê¸°
    with open(original_path / 'data.yaml', 'r') as f:
        original_config = yaml.safe_load(f)
    
    print(f"ì›ë³¸ í´ë˜ìŠ¤: {original_config['names']}")
    print(f"ì›ë³¸ í´ë˜ìŠ¤ ìˆ˜: {original_config['nc']}")
    
    # green_cone, red_coneì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
    all_classes = original_config['names']
    green_cone_idx = all_classes.index('green_cone')
    red_cone_idx = all_classes.index('red_cone')
    
    print(f"\nğŸ¯ ì„ íƒëœ í´ë˜ìŠ¤:")
    print(f"   green_cone (ì›ë³¸ ì¸ë±ìŠ¤: {green_cone_idx})")
    print(f"   red_cone (ì›ë³¸ ì¸ë±ìŠ¤: {red_cone_idx})")
    
    # ìƒˆ data.yaml ìƒì„±
    new_config = {
        'path': str(original_path.absolute()),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
        'train': 'train/images',
        'val': 'valid/images',
        'test': 'test/images' if (original_path / 'test').exists() else None,
        'nc': 2,  # green_cone, red_cone
        'names': ['green_cone', 'red_cone'],  # 0: green_cone, 1: red_cone
        'original_indices': {
            'green_cone': green_cone_idx,
            'red_cone': red_cone_idx
        }
    }
    
    # test ì—†ìœ¼ë©´ ì œê±°
    if new_config['test'] is None:
        del new_config['test']
    
    # ì €ì¥
    yaml_path = output_path / 'data_cone_only.yaml'
    with open(yaml_path, 'w') as f:
        yaml.dump(new_config, f, default_flow_style=False, sort_keys=False)
    
    print(f"\nâœ… ìƒì„± ì™„ë£Œ: {yaml_path}")
    print(f"\nğŸ“‹ ìƒˆ data.yaml ë‚´ìš©:")
    print(f"   path: {new_config['path']}")
    print(f"   train: {new_config['train']}")
    print(f"   val: {new_config['val']}")
    print(f"   nc: {new_config['nc']}")
    print(f"   names: {new_config['names']}")
    print("=" * 60)
    
    return str(yaml_path), (green_cone_idx, red_cone_idx)


def filter_labels_for_cones(dataset_path: str, green_idx: int, red_idx: int):
    """
    ë¼ë²¨ íŒŒì¼ì—ì„œ green_cone, red_coneë§Œ í•„í„°ë§
    (ì‹¤ì œë¡œëŠ” YOLOê°€ ì•Œì•„ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì„ íƒì‚¬í•­)
    """
    dataset_path = Path(dataset_path)
    
    print("\nğŸ’¡ íŒ: YOLOëŠ” ì§€ì •ëœ í´ë˜ìŠ¤ë§Œ ìë™ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤")
    print("   ë¼ë²¨ íŒŒì¼ ìˆ˜ì • ë¶ˆí•„ìš”!")
    
    # í†µê³„ë§Œ ì¶œë ¥
    splits = ['train', 'valid']
    for split in splits:
        label_dir = dataset_path / split / 'labels'
        if not label_dir.exists():
            continue
        
        total_objects = 0
        cone_objects = 0
        
        for label_file in label_dir.glob('*.txt'):
            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) > 0:
                        cls_idx = int(parts[0])
                        total_objects += 1
                        if cls_idx in [green_idx, red_idx]:
                            cone_objects += 1
        
        print(f"\nğŸ“Š {split}:")
        print(f"   ì „ì²´ ê°ì²´: {total_objects}")
        print(f"   ì½˜ ê°ì²´: {cone_objects} ({cone_objects/total_objects*100:.1f}%)")


def check_dataset(dataset_path: str):
    dataset_path = Path(dataset_path)
    
    print("=" * 60)
    print("ğŸ“ ë°ì´í„°ì…‹ í™•ì¸")
    print("=" * 60)
    
    required = {
        'data.yaml': dataset_path / 'data.yaml',
        'train': dataset_path / 'train',
        'valid': dataset_path / 'valid',
    }
    
    all_exist = True
    for name, path in required.items():
        exists = path.exists()
        status = "âœ…" if exists else "âŒ"
        print(f"{status} {name}: {path}")
        all_exist = all_exist and exists
    
    if not all_exist:
        print("\nâš ï¸  í•„ìˆ˜ íŒŒì¼/í´ë” ì—†ìŒ!")
        return False
    
    try:
        train_imgs = list((dataset_path / 'train' / 'images').glob('*.jpg')) + \
                     list((dataset_path / 'train' / 'images').glob('*.png'))
        valid_imgs = list((dataset_path / 'valid' / 'images').glob('*.jpg')) + \
                     list((dataset_path / 'valid' / 'images').glob('*.png'))
        
        print(f"\nğŸ“Š ì´ë¯¸ì§€:")
        print(f"   Train: {len(train_imgs)}")
        print(f"   Valid: {len(valid_imgs)}")
        print(f"   Total: {len(train_imgs) + len(valid_imgs)}")
    except Exception as e:
        print(f"\nâš ï¸  ì˜¤ë¥˜: {e}")
    
    try:
        with open(dataset_path / 'data.yaml', 'r') as f:
            config = yaml.safe_load(f)
            print(f"\nğŸ“‹ ì›ë³¸ í´ë˜ìŠ¤: {config.get('names', 'N/A')}")
    except Exception as e:
        print(f"âš ï¸  yaml ì˜¤ë¥˜: {e}")
    
    print("=" * 60)
    return True


def train_cone_detector(
    dataset_path: str = './docking',
    model_size: str = 'n',
    epochs: int = 100,
    img_size: int = 640,
    batch_size: int = 16,
    project_name: str = 'kaboat_cone_only',
    device: str = 'auto'
):
    """
    ì½˜ ê²€ì¶œê¸° í›ˆë ¨ (green_cone, red_coneë§Œ)
    """
    
    # ë°ì´í„°ì…‹ í™•ì¸
    if not check_dataset(dataset_path):
        return None
    
    # ì½˜ ì „ìš© yaml ìƒì„±
    cone_yaml_path, (green_idx, red_idx) = create_cone_only_yaml(dataset_path)
    
    # í†µê³„ ì¶œë ¥
    filter_labels_for_cones(dataset_path, green_idx, red_idx)
    
    # ë””ë°”ì´ìŠ¤ ê°ì§€
    if device == 'auto':
        device, device_name = detect_device()
    else:
        device_name = device
    
    # CPU ë°°ì¹˜ ì¡°ì •
    if device == 'cpu' and batch_size > 8:
        batch_size = 8
        print(f"\nâš ï¸  CPU: ë°°ì¹˜ â†’ {batch_size}")
    
    print("\n" + "=" * 60)
    print("ğŸš€ ì½˜ ê²€ì¶œê¸° í›ˆë ¨ ì‹œì‘")
    print("=" * 60)
    print(f"í”„ë¡œì íŠ¸: {project_name}")
    print(f"ëŒ€ìƒ í´ë˜ìŠ¤: green_cone, red_cone")
    print(f"ëª¨ë¸: YOLOv8{model_size}")
    print(f"ì—í¬í¬: {epochs}")
    print(f"ë°°ì¹˜: {batch_size}")
    print(f"ë””ë°”ì´ìŠ¤: {device_name}")
    print("=" * 60)
    
    model = YOLO(f'yolov8{model_size}.pt')
    
    try:
        results = model.train(
            data=cone_yaml_path,  # ì½˜ ì „ìš© yaml ì‚¬ìš©!
            epochs=epochs,
            imgsz=img_size,
            batch=batch_size,
            name=project_name,
            device=device,
            
            # ìµœì í™”
            patience=50,
            save=True,
            save_period=10,
            
            # Augmentation (ì½˜ íŠ¹í™”)
            hsv_h=0.015,
            hsv_s=0.7,
            hsv_v=0.4,
            degrees=20,      # íšŒì „ ì¦ê°•
            translate=0.1,
            scale=0.5,
            fliplr=0.5,      # ì¢Œìš° ë°˜ì „
            mosaic=1.0,
            
            # ì„±ëŠ¥
            optimizer='AdamW',
            lr0=0.01,
            lrf=0.01,
            cos_lr=True,
            workers=4 if device == 'cpu' else 8,
        )
        
        print("\n" + "=" * 60)
        print("âœ… í›ˆë ¨ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“ ê²°ê³¼: runs/detect/{project_name}/")
        print(f"ğŸ† best.pt: runs/detect/{project_name}/weights/best.pt")
        print(f"ğŸ“Š ê·¸ë˜í”„: runs/detect/{project_name}/results.png")
        print("=" * 60)
        
        print("\nğŸ¯ ì‹¤ì „ ì‚¬ìš©:")
        print("```python")
        print(f"model = YOLO('runs/detect/{project_name}/weights/best.pt')")
        print("results = model('test.jpg')")
        print("for r in results:")
        print("    for box in r.boxes:")
        print("        cls = r.names[int(box.cls[0])]")
        print("        if cls == 'green_cone':")
        print("            print('ì´ˆë¡ ì½˜ ë°œê²¬!')")
        print("        elif cls == 'red_cone':")
        print("            print('ë¹¨ê°„ ì½˜ ë°œê²¬!')")
        print("```")
        
        return results
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ì¤‘ë‹¨")
        return None
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None


def validate_cone_model(model_path: str, data_yaml: str):
    """ì½˜ ëª¨ë¸ ê²€ì¦"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ì½˜ ëª¨ë¸ ê²€ì¦")
    print("=" * 60)
    
    try:
        model = YOLO(model_path)
        results = model.val(data=data_yaml)
        
        print(f"\nğŸ“ˆ ì„±ëŠ¥:")
        print(f"   mAP50: {results.box.map50:.3f}")
        print(f"   mAP50-95: {results.box.map:.3f}")
        print(f"   Precision: {results.box.p:.3f}")
        print(f"   Recall: {results.box.r:.3f}")
        
        # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
        print(f"\nğŸ“Š í´ë˜ìŠ¤ë³„:")
        for i, name in enumerate(results.names.values()):
            print(f"   {name}: mAP50 = {results.box.maps[i]:.3f}")
        
        map50 = results.box.map50
        if map50 >= 0.9:
            print("\n   ğŸŒŸ í›Œë¥­í•¨!")
        elif map50 >= 0.7:
            print("\n   âœ… ì–‘í˜¸í•¨")
        elif map50 >= 0.5:
            print("\n   âš ï¸  ê°œì„  í•„ìš”")
        else:
            print("\n   âŒ ì¬í›ˆë ¨ ê¶Œì¥")
        
        print("=" * 60)
        return results
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return None


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='KABOAT ì½˜ ê²€ì¶œê¸° (green_cone, red_cone)')
    parser.add_argument('--dataset', type=str, default='./yl')
    parser.add_argument('--model', type=str, default='n', choices=['n', 's', 'm'])
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--img-size', type=int, default=640)
    parser.add_argument('--batch', type=int, default=16)
    parser.add_argument('--device', type=str, default='auto')
    parser.add_argument('--name', type=str, default='kaboat_cone_only')
    parser.add_argument('--mode', type=str, default='train', 
                       choices=['train', 'check', 'validate'])
    parser.add_argument('--weights', type=str, 
                       default='runs/detect/kaboat_cone_only/weights/best.pt')
    
    args = parser.parse_args()
    
    print("\n" + "=" * 60)
    print("ğŸ–¥ï¸  ì‹œìŠ¤í…œ")
    print("=" * 60)
    print(f"PyTorch: {torch.__version__}")
    print(f"CUDA: {torch.cuda.is_available()}")
    print("=" * 60)
    
    if args.mode == 'check':
        check_dataset(args.dataset)
        # ì½˜ ì „ìš© yamlë„ ìƒì„±
        create_cone_only_yaml(args.dataset)
        
    elif args.mode == 'train':
        train_cone_detector(
            dataset_path=args.dataset,
            model_size=args.model,
            epochs=args.epochs,
            img_size=args.img_size,
            batch_size=args.batch,
            project_name=args.name,
            device=args.device
        )
        
    elif args.mode == 'validate':
        yaml_path = './cone_only/data_cone_only.yaml'
        validate_cone_model(args.weights, yaml_path)


if __name__ == '__main__':
    main()