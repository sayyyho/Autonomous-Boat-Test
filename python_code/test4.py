#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Phase1: Navigation through Gates + Yellow Buoy Stop + Forward to Dock Area (ROS2 Version)
- (New) Green-priority overlap: Overlapping red/green detections are treated as GREEN.
- (New) Aligned-gate logic: Only passes through horizontally-aligned (same Y-level) pairs.
- Depth fallback for navigation
- Yellow buoy detection: approach to within 5m, wait 5s, then move forward toward dock
"""

import time
import subprocess
from typing import List, Tuple, Optional, Dict
import cv2
import numpy as np

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge

# ----------------------------
# ---- ì„¤ì • íŒŒë¼ë¯¸í„° ì˜ì—­ ----
# ----------------------------
GPIOSET_PATH = '/usr/bin/gpioset'
CHIP = 'gpiochip4'
MOTOR_A_FRONT = 19
MOTOR_A_BACK = 26
MOTOR_B_FRONT = 21
MOTOR_B_BACK = 20

COLOR_W, COLOR_H = 640, 480

FORWARD_SPEED_TIME = 0.2
TURN_90_TIME = 1.1
TURN_SMALL_TIME = 0.4
SCAN_TURN_TIME = 1.0
APPROACH_FORWARD_TIME = 0.5
DEPTH_SAFE_DISTANCE = 1.0

# í¬ê¸° í•„í„°ë§ íŒŒë¼ë¯¸í„°
MIN_CONTOUR_AREA_RED = 1000
MAX_CONTOUR_AREA_RED = 50000
MIN_CONTOUR_AREA_GREEN = 500
MAX_CONTOUR_AREA_GREEN = 30000
MIN_CONTOUR_AREA_YELLOW = 1000
MAX_CONTOUR_AREA_YELLOW = 40000

# ì¢…íš¡ë¹„ ì œí•œ
MIN_ASPECT_RATIO = 0.3
MAX_ASPECT_RATIO = 3.0
MIN_SIZE_PIXELS = 20  # ìµœì†Œ ê°€ë¡œ/ì„¸ë¡œ í”½ì…€

# --- â­ï¸ [ë¡œì§ ìˆ˜ì • 1] ìˆ˜í‰ ì •ë ¬ ê²Œì´íŠ¸ í—ˆìš© ì˜¤ì°¨ (í”½ì…€) ---
# ë‘ ë¶€í‘œì˜ ì¤‘ì‹¬ Yì¢Œí‘œê°€ ì´ ê°’ ì´ë‚´ì—¬ì•¼ ê²Œì´íŠ¸ë¡œ ì¸ì •
Y_ALIGNMENT_THRESHOLD_PX = 75

GATE_CENTER_DEADZONE = 40
DEPTH_SECTOR_WIDTH = 60
DEPTH_SAMPLE_Y = int(COLOR_H * 0.5)
YELLOW_STOP_DISTANCE = 5.0
YELLOW_WAIT_TIME = 5.0
AFTER_YELLOW_FORWARD_TIME = 3.0

# Cìí˜• íŠ¸ë™ ëŒ€ì‘: ì§€ì†ì ì¸ ì¢Œìš° ìŠ¤ìº”
CONTINUOUS_SCAN_INTERVAL = 2.0
GATE_LOST_THRESHOLD = 3.0

# --- â­ï¸ [ë¡œì§ ìˆ˜ì • 2] HSV ë²”ìœ„ ìˆ˜ì • ---
# "ë¬¼ìƒ‰"ì„ ê°ì§€í•˜ë˜ [40, 60, 60] ëŒ€ì‹  [40, 100, 100]ì„ ì‚¬ìš©
HSV_RANGES: Dict[str, List[Tuple[np.ndarray, np.ndarray]]] = {
    'RED': [
        (np.array([0, 150, 120]), np.array([8, 255, 255])),
        (np.array([172, 150, 120]), np.array([180, 255, 255]))
    ],
    'GREEN': [
        (np.array([72, 120, 90]), np.array([92, 255, 255])),
    ],
    'YELLOW': [
        (np.array([22, 120, 120]), np.array([32, 255, 255]))
    ]
}

# ----------------------------
# ---- ìœ í‹¸ë¦¬í‹° / ëª¨í„° ì œì–´ ---
# ----------------------------
def set_motor_state(a_f: int, a_b: int, b_f: int, b_b: int) -> None:
    cmd = [GPIOSET_PATH, CHIP,
           f"{MOTOR_A_FRONT}={a_f}", f"{MOTOR_A_BACK}={a_b}",
           f"{MOTOR_B_FRONT}={b_f}", f"{MOTOR_B_BACK}={b_b}"]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except Exception:
        pass

def set_motor_state_named(state: str) -> None:
    state = state.lower()
    mapping = {
        'forward': (1, 0, 1, 0),
        'backward': (0, 1, 0, 1),
        'left': (0, 1, 1, 0),
        'right': (1, 0, 0, 1),
        'stop': (0, 0, 0, 0)
    }
    set_motor_state(*mapping.get(state, (0, 0, 0, 0)))

# ----------------------------
# ---- Vision ìœ í‹¸ ---
# ----------------------------
def mask_for_color(hsv: np.ndarray, color: str) -> np.ndarray:
    color = color.upper()
    if color not in HSV_RANGES:
        return np.zeros(hsv.shape[:2], dtype=np.uint8)
    masks = [cv2.inRange(hsv, lower, upper) for (lower, upper) in HSV_RANGES[color]]
    mask = masks[0]
    for m in masks[1:]:
        mask = cv2.bitwise_or(mask, m)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    return mask

def find_all_contours_with_size_filter(mask: np.ndarray, min_area: int, max_area: int) -> List[Tuple[int, int, int, int]]:
    """í¬ê¸°ì™€ ë¹„ìœ¨ë¡œ í•„í„°ë§ëœ ì»¨íˆ¬ì–´ ì°¾ê¸°"""
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return []
    
    valid_bbs = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        
        # ë©´ì  í•„í„°
        if area < min_area or area > max_area:
            continue
        
        x, y, w, h = cv2.boundingRect(cnt)
        
        # ì¢…íš¡ë¹„ í•„í„°
        aspect_ratio = w / h if h > 0 else 0
        if aspect_ratio < MIN_ASPECT_RATIO or aspect_ratio > MAX_ASPECT_RATIO:
            continue
        
        # ìµœì†Œ í¬ê¸° í•„í„°
        if w < MIN_SIZE_PIXELS or h < MIN_SIZE_PIXELS:
            continue
        
        valid_bbs.append((x, y, w, h))
    
    return valid_bbs

def find_largest_contour_with_size_filter(mask: np.ndarray, min_area: int, max_area: int) -> Optional[Tuple[int, int, int, int]]:
    """í¬ê¸° í•„í„°ë§ëœ ê°€ì¥ í° ì»¨íˆ¬ì–´ ì°¾ê¸°"""
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return None
    
    valid_contours = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if min_area <= area <= max_area:
            x, y, w, h = cv2.boundingRect(cnt)
            aspect_ratio = w / h if h > 0 else 0
            if MIN_ASPECT_RATIO <= aspect_ratio <= MAX_ASPECT_RATIO and w >= MIN_SIZE_PIXELS and h >= MIN_SIZE_PIXELS:
                valid_contours.append(cnt)
    
    if not valid_contours:
        return None
    
    largest = max(valid_contours, key=cv2.contourArea)
    return cv2.boundingRect(largest)

# --- â­ï¸ [ë¡œì§ ìˆ˜ì • 3] 2D ê²¹ì¹¨(Overlap) í™•ì¸ í•¨ìˆ˜ ì¶”ê°€ ---
def has_overlap(bb1: Tuple[int, int, int, int], bb2: Tuple[int, int, int, int]) -> bool:
    """ë‘ ë°”ìš´ë”© ë°•ìŠ¤(x, y, w, h)ê°€ ê²¹ì¹˜ëŠ”ì§€ 2Dë¡œ í™•ì¸"""
    x1, y1, w1, h1 = bb1
    x2, y2, w2, h2 = bb2
    
    # AABB (Axis-Aligned Bounding Box) ì¶©ëŒ ê²€ì‚¬
    if (x1 < x2 + w2 and x1 + w1 > x2 and
        y1 < y2 + h2 and y1 + h1 > y2):
        return True
    return False

# --- â­ï¸ [ë¡œì§ ìˆ˜ì • 4] 'ì´ˆë¡ ìš°ì„ ' ê²¹ì¹¨ í•„í„°ë¡œ ë³€ê²½ ---
def filter_overlapping_colors(red_bbs: List[Tuple[int, int, int, int]], 
                               green_bbs: List[Tuple[int, int, int, int]]) -> Tuple[List, List]:
    """
    ë¹¨ê°•ê³¼ ì´ˆë¡ ë°”ìš´ë”© ë°•ìŠ¤ê°€ 2Dë¡œ ê²¹ì¹˜ë©´, ì´ˆë¡ìœ¼ë¡œ ìš°ì„  ì¸ì§€ (ë¹¨ê°• ì œê±°)
    """
    filtered_red = []
    
    for red_bb in red_bbs:
        is_actually_green = False
        for green_bb in green_bbs:
            # 2D ê²¹ì¹¨ ê²€ì‚¬
            if has_overlap(red_bb, green_bb):
                is_actually_green = True
                break
        
        # ì–´ë–¤ ì´ˆë¡ê³¼ë„ ê²¹ì¹˜ì§€ ì•ŠëŠ” ë¹¨ê°•ë§Œ ìœ ì§€
        if not is_actually_green:
            filtered_red.append(red_bb)
    
    return filtered_red, green_bbs

# --- â­ï¸ [ë¡œì§ ìˆ˜ì • 5] 'ìˆ˜í‰ ì •ë ¬' ê²Œì´íŠ¸ ì°¾ê¸° ë¡œì§ìœ¼ë¡œ ë³€ê²½ ---
def find_closest_gate_pair(red_bbs: List[Tuple[int, int, int, int]], 
                           green_bbs: List[Tuple[int, int, int, int]],
                           frame_width: int) -> Optional[Tuple[Tuple[int, int, int, int], 
                                                                Tuple[int, int, int, int]]]:
    """
    ê·œì¹™(ì¢Œ=ì´ˆë¡, ìš°=ë¹¨ê°•)ê³¼ ìˆ˜í‰ ì •ë ¬(Yì¢Œí‘œ)ì„ ë§Œì¡±í•˜ëŠ”
    ê°€ì¥ ì¤‘ì•™ì— ê°€ê¹Œìš´ ê²Œì´íŠ¸ ìŒì„ ì°¾ìŒ
    """
    if not red_bbs or not green_bbs:
        return None
    
    frame_center = frame_width // 2
    min_distance = float('inf')
    best_pair = None
    
    for green_bb in green_bbs:
        gx, gy, gw, gh = green_bb
        green_cx = gx + gw // 2
        green_cy = gy + gh // 2 # Yì¢Œí‘œ ì¤‘ì‹¬
        
        for red_bb in red_bbs:
            rx, ry, rw, rh = red_bb
            red_cx = rx + rw // 2
            red_cy = ry + rh // 2 # Yì¢Œí‘œ ì¤‘ì‹¬
            
            # ê·œì¹™ 1: ì¢Œì¸¡=ì´ˆë¡, ìš°ì¸¡=ë¹¨ê°• í™•ì¸
            if green_cx >= red_cx:
                continue
            
            # ê·œì¹™ 2: ìˆ˜í‰ ì •ë ¬(Yì¢Œí‘œ) í™•ì¸
            if abs(green_cy - red_cy) > Y_ALIGNMENT_THRESHOLD_PX:
                continue
            
            # ê²Œì´íŠ¸ ì¤‘ì‹¬ ê³„ì‚°
            gate_center = (red_cx + green_cx) // 2
            
            # í”„ë ˆì„ ì¤‘ì•™ê³¼ì˜ ê±°ë¦¬
            distance = abs(gate_center - frame_center)
            
            if distance < min_distance:
                min_distance = distance
                best_pair = (red_bb, green_bb)
    
    return best_pair

# ----------------------------
# ---- Phase1 Navigator (ROS2) ----
# ----------------------------
class Phase1Navigator(Node):
    def __init__(self):
        super().__init__('phase1_navigator')
        
        # ROS2 êµ¬ë…ì ì„¤ì •
        self.bridge = CvBridge()
        self.color_subscription = self.create_subscription(
            Image,
            '/camera/camera/color/image_raw',
            self.color_callback,
            10
        )
        self.depth_subscription = self.create_subscription(
            Image,
            '/camera/camera/depth/image_rect_raw',
            self.depth_callback,
            10
        )
        
        # ìƒíƒœ ë³€ìˆ˜
        self.color_img = None
        self.depth_img = None
        self.scan_direction = 'right'
        self.last_scan_time = 0
        self.last_gate_seen_time = time.time()
        self.last_auto_scan_time = time.time()
        self.mission_complete = False
        
        self.get_logger().info("=== Phase1 Navigator ì‹œì‘ (ROS2) ===")

    def color_callback(self, msg: Image):
        """ì»¬ëŸ¬ ì´ë¯¸ì§€ ìˆ˜ì‹ """
        self.color_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        self.process_frame()

    def depth_callback(self, msg: Image):
        """ê¹Šì´ ì´ë¯¸ì§€ ìˆ˜ì‹ """
        self.depth_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')

    def get_depth_at_point(self, x: int, y: int) -> float:
        """íŠ¹ì • í”½ì…€ì˜ ê¹Šì´ ê°’ ë°˜í™˜ (ë¯¸í„° ë‹¨ìœ„)"""
        if self.depth_img is None:
            return 0.0
        try:
            # ëìŠ¤ ì´ë¯¸ì§€ í¬ë§·ì— ë”°ë¼ 'z16' (uint16) ë˜ëŠ” '32FC1' (float32) ì¼ ìˆ˜ ìˆìŒ
            # Realsense ROS ë˜í¼ëŠ” ë³´í†µ 'z16' (mm ë‹¨ìœ„)
            depth_val = self.depth_img[y, x]
            if np.issubdtype(self.depth_img.dtype, np.integer):
                return float(depth_val) / 1000.0  # mm to meters
            elif np.issubdtype(self.depth_img.dtype, np.floating):
                return float(depth_val)  # already in meters
            return 0.0
        except Exception as e:
            self.get_logger().warn(f"Get depth error: {e}")
            return 0.0

    def depth_sector_distances(self) -> Tuple[float, float, float]:
        """ì¢Œ/ì¤‘ì•™/ìš° ì„¹í„°ì˜ ìµœì†Œ ê±°ë¦¬ ê³„ì‚°"""
        if self.depth_img is None:
            return (float('inf'), float('inf'), float('inf'))
        
        cx = COLOR_W // 2
        y = DEPTH_SAMPLE_Y
        
        def sector(px_start, px_end):
            vals = []
            for px in range(px_start, px_end):
                dist = self.get_depth_at_point(px, y)
                if dist > 0.1 and dist < 20.0: # ìœ íš¨ ê±°ë¦¬ (0.1m ~ 20m)
                    vals.append(dist)
            return min(vals) if vals else float('inf')
        
        left = sector(max(0, cx - 3*DEPTH_SECTOR_WIDTH), max(0, cx - DEPTH_SECTOR_WIDTH))
        front = sector(max(0, cx - DEPTH_SECTOR_WIDTH), min(COLOR_W, cx + DEPTH_SECTOR_WIDTH))
        right = sector(min(COLOR_W-1, cx + DEPTH_SECTOR_WIDTH), min(COLOR_W, cx + 3*DEPTH_SECTOR_WIDTH))
        
        return left, front, right

    def auto_scan_for_gate(self):
        """Cìí˜• íŠ¸ë™ ëŒ€ì‘: ìë™ ì¢Œìš° ìŠ¤ìº”"""
        current_time = time.time()
        
        # ê²Œì´íŠ¸ë¥¼ ì˜¤ë˜ ëª» ë´¤ê±°ë‚˜ ì£¼ê¸°ì  ìŠ¤ìº” ì‹œê°„ì´ ë˜ë©´
        if (current_time - self.last_gate_seen_time > GATE_LOST_THRESHOLD or 
            current_time - self.last_auto_scan_time > CONTINUOUS_SCAN_INTERVAL):
            
            self.last_auto_scan_time = current_time
            self.get_logger().info(f"[AUTO SCAN] {self.scan_direction} ë°©í–¥ìœ¼ë¡œ ê²Œì´íŠ¸ íƒìƒ‰")
            
            if self.scan_direction == 'left':
                set_motor_state_named('left')
                time.sleep(SCAN_TURN_TIME * 0.5)
                self.scan_direction = 'right'
            else:
                set_motor_state_named('right')
                time.sleep(SCAN_TURN_TIME * 0.5)
                self.scan_direction = 'left'
            
            set_motor_state_named('stop')

    def process_frame(self):
        """ë©”ì¸ í”„ë¡œì„¸ì‹± ë¡œì§"""
        if self.color_img is None or self.mission_complete:
            return
        
        color_img = self.color_img.copy()
        hsv = cv2.cvtColor(color_img, cv2.COLOR_BGR2HSV)

        # ìƒ‰ìƒ ê°ì§€ (í¬ê¸° í•„í„°ë§ ì ìš©)
        mask_red = mask_for_color(hsv, 'RED')
        mask_green = mask_for_color(hsv, 'GREEN')
        mask_yellow = mask_for_color(hsv, 'YELLOW')

        red_bbs_raw = find_all_contours_with_size_filter(mask_red, MIN_CONTOUR_AREA_RED, MAX_CONTOUR_AREA_RED)
        green_bbs = find_all_contours_with_size_filter(mask_green, MIN_CONTOUR_AREA_GREEN, MAX_CONTOUR_AREA_GREEN)
        yellow_bb = find_largest_contour_with_size_filter(mask_yellow, MIN_CONTOUR_AREA_YELLOW, MAX_CONTOUR_AREA_YELLOW)

        # ğŸ”´ğŸŸ¢ (ìˆ˜ì •) 'ì´ˆë¡ ìš°ì„ ' 2D ê²¹ì¹¨ í•„í„° ì ìš©
        red_bbs, green_bbs = filter_overlapping_colors(red_bbs_raw, green_bbs)

        # ë””ë²„ê·¸: í•„í„°ë§ëœ ë¶€í‘œ í‘œì‹œ
        for bb in red_bbs:
            x, y, w, h = bb
            area = w * h
            cv2.rectangle(color_img, (x, y), (x+w, y+h), (0, 0, 255), 2)
            cv2.putText(color_img, f"RED({area})", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        for bb in green_bbs:
            x, y, w, h = bb
            area = w * h
            cv2.rectangle(color_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(color_img, f"GREEN({area})", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # ğŸŸ¡ ë…¸ë€ë¶€í‘œ ì²˜ë¦¬ - ê²Œì´íŠ¸ê°€ ì—†ì„ ë•Œë§Œ ê°ì§€
        if yellow_bb and not (red_bbs or green_bbs):
            self.last_gate_seen_time = time.time() # ë…¸ë€ ë¶€í‘œë„ 'í‘œì‹'ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ìŠ¤ìº” íƒ€ì´ë¨¸ ë¦¬ì…‹
            self.get_logger().info("ğŸŸ¡ ë…¸ë€ë¶€í‘œ ê°ì§€")
            x, y, w, h = yellow_bb
            cv2.rectangle(color_img, (x, y), (x+w, y+h), (0, 255, 255), 2)
            cv2.putText(color_img, "YELLOW", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            
            if self.approach_yellow_and_wait(yellow_bb, color_img):
                self.get_logger().info(f"ğŸš¢ ë„í‚¹ êµ¬ì—­ìœ¼ë¡œ {AFTER_YELLOW_FORWARD_TIME}ì´ˆ ì „ì§„")
                set_motor_state_named('forward')
                time.sleep(AFTER_YELLOW_FORWARD_TIME)
                set_motor_state_named('stop')
                self.get_logger().info("âœ… Phase1 ì™„ë£Œ")
                self.mission_complete = True

        # ğŸŸ¥ğŸŸ© ê²Œì´íŠ¸ ì²˜ë¦¬: (ìˆ˜ì •) 'ìˆ˜í‰ ì •ë ¬'ëœ ìŒ ì°¾ê¸°
        elif red_bbs and green_bbs:
            self.last_gate_seen_time = time.time()
            
            gate_pair = find_closest_gate_pair(red_bbs, green_bbs, color_img.shape[1])
            
            if gate_pair:
                red_bb, green_bb = gate_pair
                
                rx, ry, rw, rh = red_bb
                gx, gy, gw, gh = green_bb
                
                red_cx, green_cx = rx + rw//2, gx + gw//2
                gate_center = (red_cx + green_cx)//2
                
                # ì„ íƒëœ ê²Œì´íŠ¸ ìŒ ê°•ì¡° í‘œì‹œ
                cv2.rectangle(color_img, (rx, ry), (rx+rw, ry+rh), (0, 0, 255), 3)
                cv2.rectangle(color_img, (gx, gy), (gx+gw, gy+gh), (0, 255, 0), 3)
                cv2.line(color_img, (gate_center, 0), (gate_center, COLOR_H), (255, 255, 0), 2)
                cv2.putText(color_img, "GATE DETECTED", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                
                self.approach_gate(gate_center, color_img)
            else:
                # --- â­ï¸ [ë¡œì§ ìˆ˜ì • 6] ìœ íš¨ ê²Œì´íŠ¸ ì—†ì„ ì‹œ Depth Follow ---
                self.get_logger().info("ë¶€í‘œëŠ” ë³´ì´ë‚˜ ìœ íš¨í•œ ìˆ˜í‰ ê²Œì´íŠ¸ê°€ ì—†ìŒ -> Depth Follow")
                cv2.putText(color_img, "No Aligned Gate -> Depth", (20, 40), 
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                self.depth_follow(color_img)
            
        elif red_bbs or green_bbs:
            # í•œìª½ ë¶€í‘œë§Œ ë³´ì¼ ë•Œ
            self.last_gate_seen_time = time.time() # í•œìª½ì´ë¼ë„ ë³´ì´ë©´ íƒ€ì´ë¨¸ ë¦¬ì…‹
            visible_color = 'RED' if red_bbs else 'GREEN'
            bb = red_bbs[0] if red_bbs else green_bbs[0]
            
            cx = bb[0] + bb[2]//2
            cv2.putText(color_img, f"SCANNING for {visible_color}", (20, 40), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            self.single_color_scan(visible_color, cx, color_img)
        
        else:
            # --- â­ï¸ [ë¡œì§ ìˆ˜ì • 7] ë¶€í‘œê°€ ì•„ì˜ˆ ì—†ì„ ì‹œ Depth Follow ---
            # (auto_scan_for_gate ëŒ€ì‹  depth_followë¡œ ë³€ê²½í•˜ì—¬ ì•ˆì „ì„± í™•ë³´)
            cv2.putText(color_img, "No Buoys -> Depth Follow", (20, 40), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            self.depth_follow(color_img)
            
            # C-íŠ¸ë™ ë“±ì„ ìœ„í•œ ì£¼ê¸°ì  ìŠ¤ìº”ì€ ë³„ë„ë¡œ ê³„ì† í™•ì¸
            self.auto_scan_for_gate()
        
        cv2.imshow("Phase1 View", color_img)
        cv2.waitKey(1)

    def approach_gate(self, gate_center: int, frame: np.ndarray):
        frame_cx = frame.shape[1]//2
        error = gate_center - frame_cx
        if abs(error) <= GATE_CENTER_DEADZONE:
            self.get_logger().info("ê²Œì´íŠ¸ ì¤‘ì•™ ì •ë ¬ ì™„ë£Œ â†’ ì „ì§„")
            set_motor_state_named('forward'); time.sleep(APPROACH_FORWARD_TIME)
        elif error > 0:
            self.get_logger().info("ê²Œì´íŠ¸ ìš°ì¸¡ â†’ ìš°íšŒì „")
            set_motor_state_named('right'); time.sleep(TURN_SMALL_TIME)
        else:
            self.get_logger().info("ê²Œì´íŠ¸ ì¢Œì¸¡ â†’ ì¢ŒíšŒì „")
            set_motor_state_named('left'); time.sleep(TURN_SMALL_TIME)
        set_motor_state_named('stop')

    def single_color_scan(self, color: str, cx: int, frame: np.ndarray):
        current_time = time.time()
        
        if current_time - self.last_scan_time < 1.0:
            return
        
        self.last_scan_time = current_time
        
        self.get_logger().info(f"[SCAN] {color} ë‹¨ë… ê°ì§€ â†’ {self.scan_direction} ë°©í–¥ìœ¼ë¡œ 1ì´ˆ ìŠ¤ìº”")
        
        if self.scan_direction == 'left':
            set_motor_state_named('left')
            time.sleep(SCAN_TURN_TIME)
            self.scan_direction = 'right'
        else:
            set_motor_state_named('right')
            time.sleep(SCAN_TURN_TIME)
            self.scan_direction = 'left'
        
        set_motor_state_named('stop')

    def depth_follow(self, frame: np.ndarray):
        """ê²Œì´íŠ¸ë‚˜ ë¶€í‘œê°€ ì—†ì„ ë•Œ, ê¹Šì´ ê¸°ë°˜ íšŒí”¼/ì „ì§„ ë™ì‘"""
        left, front, right = self.depth_sector_distances()
        
        self.get_logger().info(f"[DEPTH] L:{left:.2f} / F:{front:.2f} / R:{right:.2f}")
        if front > DEPTH_SAFE_DISTANCE and front != float('inf'):
            self.get_logger().info("ì „ë°© ì•ˆì „ â†’ ì „ì§„")
            set_motor_state_named('forward')
            time.sleep(FORWARD_SPEED_TIME)
        elif left > right:
            self.get_logger().info("ì¢Œì¸¡ ê³µê°„ ì—¬ìœ  â†’ ì¢ŒíšŒì „")
            set_motor_state_named('left')
            time.sleep(TURN_SMALL_TIME)
        else:
            self.get_logger().info("ìš°ì¸¡ ê³µê°„ ì—¬ìœ  â†’ ìš°íšŒì „")
            set_motor_state_named('right')
            time.sleep(TURN_SMALL_TIME)
        
        set_motor_state_named('stop')

    def approach_yellow_and_wait(self, yellow_bb: Tuple[int, int, int, int], frame: np.ndarray) -> bool:
        """ë…¸ë€ë¶€í‘œ ì ‘ê·¼ ë° ì¼ì • ê±°ë¦¬ ë‚´ ì •ì§€ ëŒ€ê¸°"""
        x, y, w, h = yellow_bb
        cx = x + w // 2
        cy = y + h // 2
        
        depth = self.get_depth_at_point(cx, cy)
        
        if depth == 0 or np.isnan(depth) or depth > 20.0: # ìœ íš¨ ê±°ë¦¬ 20m ì´ˆê³¼ ì‹œ ë¬´ì‹œ
            self.get_logger().info(f"[YELLOW] ê¹Šì´ ì •ë³´ ì—†ìŒ/ìœ íš¨í•˜ì§€ ì•ŠìŒ ({depth:.2f}m) â†’ ì •ì§€")
            set_motor_state_named('stop')
            return False
        
        self.get_logger().info(f"[YELLOW] ë…¸ë€ë¶€í‘œ ê±°ë¦¬: {depth:.2f}m")
        
        if depth > YELLOW_STOP_DISTANCE:
            # ê±°ë¦¬ê°€ ë©€ë©´, ì¤‘ì‹¬ìœ¼ë¡œ ì •ë ¬í•˜ë©° ì „ì§„
            frame_cx = frame.shape[1] // 2
            if cx < frame_cx - GATE_CENTER_DEADZONE:
                self.get_logger().info("ë…¸ë€ë¶€í‘œ ì¢Œì¸¡ â†’ ì¢ŒíšŒì „")
                set_motor_state_named('left'); time.sleep(TURN_SMALL_TIME)
            elif cx > frame_cx + GATE_CENTER_DEADZONE:
                self.get_logger().info("ë…¸ë€ë¶€í‘œ ìš°ì¸¡ â†’ ìš°íšŒì „")
                set_motor_state_named('right'); time.sleep(TURN_SMALL_TIME)
            else:
                self.get_logger().info("5m ì´ìƒ â†’ ì ‘ê·¼ ê³„ì† (ì „ì§„)")
                set_motor_state_named('forward'); time.sleep(APPROACH_FORWARD_TIME)
            set_motor_state_named('stop')
            return False
        else:
            # ëª©í‘œ ê±°ë¦¬ ì´ë‚´ ë„ë‹¬
            self.get_logger().info("ğŸŸ¡ 5m ì´ë‚´ ë„ë‹¬ â†’ ì •ì§€ ë° 5ì´ˆ ëŒ€ê¸°")
            set_motor_state_named('stop')
            
            for i in range(int(YELLOW_WAIT_TIME), 0, -1):
                self.get_logger().info(f"â±ï¸  {i}ì´ˆ...")
                time.sleep(1)
            
            self.get_logger().info("âœ… 5ì´ˆ ëŒ€ê¸° ì™„ë£Œ!")
            return True

def main(args=None):
    rclpy.init(args=args)
    node = Phase1Navigator()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        set_motor_state_named('stop')
        cv2.destroyAllWindows()
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()