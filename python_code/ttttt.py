#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Phase1: Navigation through Gates + Yellow Buoy Stop + Forward to Dock Area (ROS2 Version)
- Arduino-based motor control via serial communication
- Green-priority overlap: Overlapping red/green detections are treated as GREEN
- Aligned-gate logic: Only passes through horizontally-aligned (same Y-level) pairs
- â­ (New) Sequential Gate Memory: Remembers one buoy (e.g., Green) and scans for its pair (e.g., Red) to count as a pass.
- â­ (New) Robust HSV Ranges: Wider S/V ranges for better detection in varied lighting.
- Yellow buoy detection: approach to within 5m, wait 5s, then move forward toward dock
"""

import time
import serial
from typing import List, Tuple, Optional, Dict
import cv2
import numpy as np

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge

# ----------------------------
# ---- ì„¤ì • íŒŒë¼ë¯¸í„° ì˜ì—­ ----
# ----------------------------
# ì•„ë‘ì´ë…¸ ì‹œë¦¬ì–¼ ì„¤ì •
SERIAL_PORT = '/dev/ttyACM0'
BAUD_RATE = 9600
DEFAULT_SPEED = '5'  # ê¸°ë³¸ ì†ë„ (0-9)

# â­ ë¯¸ì…˜ ì„¤ì •
TOTAL_GATES = int(input("í†µê³¼í•´ì•¼ í•  ê²Œì´íŠ¸ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ") or "5")  # ê¸°ë³¸ê°’ 5ê°œ
print(f"ì´ {TOTAL_GATES}ê°œì˜ ê²Œì´íŠ¸ë¥¼ í†µê³¼í•©ë‹ˆë‹¤.")

COLOR_W, COLOR_H = 640, 480

FORWARD_SPEED_TIME = 0.1
TURN_90_TIME = 1.1
TURN_SMALL_TIME = 0.4
SCAN_TURN_TIME = 1.0
APPROACH_FORWARD_TIME = 0.3
DEPTH_SAFE_DISTANCE = 1.0

# í¬ê¸° í•„í„°ë§ íŒŒë¼ë¯¸í„°
MIN_CONTOUR_AREA_RED = 500
MAX_CONTOUR_AREA_RED = 50000
MIN_CONTOUR_AREA_GREEN = 500
MAX_CONTOUR_AREA_GREEN = 50000
MIN_CONTOUR_AREA_YELLOW = 500
MAX_CONTOUR_AREA_YELLOW = 40000

# ì¢…íš¡ë¹„ ì œí•œ
MIN_ASPECT_RATIO = 0.3
MAX_ASPECT_RATIO = 3.0
MIN_SIZE_PIXELS = 20  # ìµœì†Œ ê°€ë¡œ/ì„¸ë¡œ í”½ì…€

# ìˆ˜í‰ ì •ë ¬ ê²Œì´íŠ¸ í—ˆìš© ì˜¤ì°¨ (í”½ì…€)
Y_ALIGNMENT_THRESHOLD_PX = 75

GATE_CENTER_DEADZONE = 40
DEPTH_SECTOR_WIDTH = 60
DEPTH_SAMPLE_Y = int(COLOR_H * 0.5)
YELLOW_STOP_DISTANCE = 5.0
YELLOW_WAIT_TIME = 5.0
AFTER_YELLOW_FORWARD_TIME = 2.0

# Cìí˜• íŠ¸ë™ ëŒ€ì‘: ì§€ì†ì ì¸ ì¢Œìš° ìŠ¤ìº”
CONTINUOUS_SCAN_INTERVAL = 2.0
GATE_LOST_THRESHOLD = 3.0
SEQUENTIAL_GATE_MEMORY_TIME = 5.0 # â­ ìˆœì°¨ ê²Œì´íŠ¸ ê¸°ì–µ ì‹œê°„ (5ì´ˆ)

# --- â­ï¸ [ë¡œì§ ìˆ˜ì • 2] HSV ë²”ìœ„ í™•ì¥ ---
HSV_RANGES: Dict[str, List[Tuple[np.ndarray, np.ndarray]]] = {
    'RED': [
        (np.array([0, 100, 100]), np.array([10, 255, 255])),
        (np.array([165, 100, 100]), np.array([180, 255, 255]))
    ],
    'GREEN': [
        # 40(green)ë¶€í„° 105(cyan/teal)ê¹Œì§€, S/V ìµœì†Ÿê°’ 70ìœ¼ë¡œ ì„¤ì •
        (np.array([40, 70, 70]), np.array([105, 255, 255])),
    ],
    'YELLOW': [
        (np.array([22, 120, 120]), np.array([32, 255, 255]))
    ]
}

# ----------------------------
# ---- ì•„ë‘ì´ë…¸ ëª¨í„° ì œì–´ í´ë˜ìŠ¤ ----
# ----------------------------
class ArduinoMotorController:
    """ì•„ë‘ì´ë…¸ì™€ ì‹œë¦¬ì–¼ í†µì‹ ìœ¼ë¡œ ëª¨í„° ì œì–´"""
    
    def __init__(self, port: str = SERIAL_PORT, baudrate: int = BAUD_RATE):
        self.ser = None
        self.current_command = b'x'
        self.current_speed = DEFAULT_SPEED.encode()
        
        try:
            self.ser = serial.Serial(port, baudrate, timeout=1)
            time.sleep(2)
            self.set_speed(DEFAULT_SPEED)
            self.stop()
            print(f"âœ… ì•„ë‘ì´ë…¸ ì—°ê²° ì„±ê³µ: {port}")
        except serial.SerialException as e:
            print(f"âŒ ì•„ë‘ì´ë…¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            print("í¬íŠ¸ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”: sudo usermod -a -G dialout $USER")
            
    def send_command(self, command: bytes):
        """ì•„ë‘ì´ë…¸ì— ëª…ë ¹ ì „ì†¡"""
        if self.ser and self.ser.is_open:
            try:
                self.ser.write(command)
                self.current_command = command
                time.sleep(0.01)
            except Exception as e:
                print(f"ëª…ë ¹ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    def set_speed(self, speed: str):
        """ì†ë„ ì„¤ì • (0-9)"""
        if speed.isdigit() and '0' <= speed <= '9':
            self.current_speed = speed.encode()
            self.send_command(self.current_speed)
    
    def forward(self): self.send_command(b'w')
    def backward(self): self.send_command(b's')
    def left(self): self.send_command(b'a')
    def right(self): self.send_command(b'd')
    def stop(self): self.send_command(b'x')
    
    def close(self):
        """ì‹œë¦¬ì–¼ í¬íŠ¸ ë‹«ê¸°"""
        if self.ser and self.ser.is_open:
            self.stop()
            self.ser.close()
            print("âœ… ì•„ë‘ì´ë…¸ ì—°ê²° ì¢…ë£Œ")

# ì „ì—­ ëª¨í„° ì»¨íŠ¸ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
motor_controller = None

def init_motor_controller():
    """ëª¨í„° ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
    global motor_controller
    motor_controller = ArduinoMotorController()
    return motor_controller

def set_motor_state_named(state: str) -> None:
    """ëª…ëª…ëœ ìƒíƒœë¡œ ëª¨í„° ì œì–´"""
    global motor_controller
    if not motor_controller: return
    state = state.lower()
    mapping = {'forward': motor_controller.forward, 'backward': motor_controller.backward,
               'left': motor_controller.left, 'right': motor_controller.right, 'stop': motor_controller.stop}
    action = mapping.get(state)
    if action: action()

# ----------------------------
# ---- Vision ìœ í‹¸ ---
# ----------------------------
def mask_for_color(hsv: np.ndarray, color: str) -> np.ndarray:
    color = color.upper()
    if color not in HSV_RANGES:
        return np.zeros(hsv.shape[:2], dtype=np.uint8)
    masks = [cv2.inRange(hsv, lower, upper) for (lower, upper) in HSV_RANGES[color]]
    mask = masks[0]
    for m in masks[1:]:
        mask = cv2.bitwise_or(mask, m)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    return mask

def find_all_contours_with_size_filter(mask: np.ndarray, min_area: int, max_area: int) -> List[Tuple[int, int, int, int]]:
    """í¬ê¸°ì™€ ë¹„ìœ¨ë¡œ í•„í„°ë§ëœ ì»¨íˆ¬ì–´ ì°¾ê¸°"""
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    valid_bbs = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if not (min_area <= area): continue
        x, y, w, h = cv2.boundingRect(cnt)
        if w < MIN_SIZE_PIXELS or h < MIN_SIZE_PIXELS: continue
        aspect_ratio = w / h if h > 0 else 0
        if not (MIN_ASPECT_RATIO <= aspect_ratio <= MAX_ASPECT_RATIO): continue
        valid_bbs.append((x, y, w, h))
    return valid_bbs

def find_largest_contour_with_size_filter(mask: np.ndarray, min_area: int, max_area: int) -> Optional[Tuple[int, int, int, int]]:
    """í¬ê¸° í•„í„°ë§ëœ ê°€ì¥ í° ì»¨íˆ¬ì–´ ì°¾ê¸°"""
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    valid_contours = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if min_area <= area:
            x, y, w, h = cv2.boundingRect(cnt)
            aspect_ratio = w / h if h > 0 else 0
            if MIN_ASPECT_RATIO <= aspect_ratio <= MAX_ASPECT_RATIO and w >= MIN_SIZE_PIXELS and h >= MIN_SIZE_PIXELS:
                valid_contours.append(cnt)
    if not valid_contours: return None
    largest = max(valid_contours, key=cv2.contourArea)
    return cv2.boundingRect(largest)

def has_overlap(bb1: Tuple[int, int, int, int], bb2: Tuple[int, int, int, int]) -> bool:
    """ë‘ ë°”ìš´ë”© ë°•ìŠ¤(x, y, w, h)ê°€ ê²¹ì¹˜ëŠ”ì§€ 2Dë¡œ í™•ì¸"""
    x1, y1, w1, h1 = bb1
    x2, y2, w2, h2 = bb2
    return (x1 < x2 + w2 and x1 + w1 > x2 and y1 < y2 + h2 and y1 + h1 > y2)

def filter_overlapping_colors(red_bbs: List[Tuple[int, int, int, int]], 
                               green_bbs: List[Tuple[int, int, int, int]]) -> Tuple[List, List]:
    """ë¹¨ê°•ê³¼ ì´ˆë¡ ë°”ìš´ë”© ë°•ìŠ¤ê°€ 2Dë¡œ ê²¹ì¹˜ë©´, ì´ˆë¡ìœ¼ë¡œ ìš°ì„  ì¸ì§€ (ë¹¨ê°• ì œê±°)"""
    filtered_red = []
    for red_bb in red_bbs:
        is_actually_green = False
        for green_bb in green_bbs:
            if has_overlap(red_bb, green_bb):
                is_actually_green = True
                break
        if not is_actually_green:
            filtered_red.append(red_bb)
    return filtered_red, green_bbs

def find_closest_gate_pair(red_bbs: List[Tuple[int, int, int, int]], 
                           green_bbs: List[Tuple[int, int, int, int]],
                           frame_width: int) -> Optional[Tuple[Tuple[int, int, int, int], 
                                                                Tuple[int, int, int, int]]]:
    """ê·œì¹™(ì¢Œ=ì´ˆë¡, ìš°=ë¹¨ê°•)ê³¼ ìˆ˜í‰ ì •ë ¬(Yì¢Œí‘œ)ì„ ë§Œì¡±í•˜ëŠ” ê°€ì¥ ì¤‘ì•™ì— ê°€ê¹Œìš´ ê²Œì´íŠ¸ ìŒì„ ì°¾ìŒ"""
    if not red_bbs or not green_bbs: return None
    frame_center = frame_width // 2
    min_distance = float('inf')
    best_pair = None
    
    for green_bb in green_bbs:
        gx, gy, gw, gh = green_bb
        green_cx, green_cy = gx + gw // 2, gy + gh // 2
        for red_bb in red_bbs:
            rx, ry, rw, rh = red_bb
            red_cx, red_cy = rx + rw // 2, ry + rh // 2
            
            if green_cx >= red_cx: continue # ê·œì¹™ 1: ì¢Œì¸¡=ì´ˆë¡, ìš°ì¸¡=ë¹¨ê°•
            if abs(green_cy - red_cy) > Y_ALIGNMENT_THRESHOLD_PX: continue # ê·œì¹™ 2: ìˆ˜í‰ ì •ë ¬
            
            gate_center = (red_cx + green_cx) // 2
            distance = abs(gate_center - frame_center)
            
            if distance < min_distance:
                min_distance = distance
                best_pair = (red_bb, green_bb)
    return best_pair

# ----------------------------
# ---- Phase1 Navigator (ROS2) ----
# ----------------------------
class Phase1Navigator(Node):
    def __init__(self):
        super().__init__('phase1_navigator')
        
        # ëª¨í„° ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™”
        self.motor = init_motor_controller()
        
        # ROS2 êµ¬ë…ì ì„¤ì •
        self.bridge = CvBridge()
        self.color_subscription = self.create_subscription(
            Image, '/camera/camera/color/image_raw', self.color_callback, 10)
        self.depth_subscription = self.create_subscription(
            Image, '/camera/camera/depth/image_rect_raw', self.depth_callback, 10)
        
        # ìƒíƒœ ë³€ìˆ˜
        self.color_img = None
        self.depth_img = None
        self.scan_direction = 'right'
        self.last_scan_time = 0
        self.last_gate_seen_time = time.time()
        self.last_auto_scan_time = time.time()
        self.mission_complete = False
        
        # ë¯¸ì…˜ ë‹¨ê³„ ê´€ë¦¬ ë³€ìˆ˜
        self.mission_stage = 'NAVIGATION'
        self.gates_passed = 0
        self.gate_passing_state = 'SEARCHING'
        
        # --- â­ï¸ [ë¡œì§ ìˆ˜ì • 1] ìˆœì°¨ ê²Œì´íŠ¸ ê¸°ì–µ ë³€ìˆ˜ ì¶”ê°€ ---
        self.seen_buoy_half = None  # ì˜ˆ: 'GREEN_LEFT' ë˜ëŠ” 'RED_RIGHT'
        self.last_seen_half_time = time.time() # ì²« ì§ì„ ë³¸ ì‹œê°„
        
        self.get_logger().info("=== Phase1 Navigator ì‹œì‘ (ROS2 + Arduino) ===")

    def color_callback(self, msg: Image):
        self.color_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        self.process_frame()

    def depth_callback(self, msg: Image):
        self.depth_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')

    def get_depth_at_point(self, x: int, y: int) -> float:
        """íŠ¹ì • í”½ì…€ì˜ ê¹Šì´ ê°’ ë°˜í™˜ (ë¯¸í„° ë‹¨ìœ„)"""
        if self.depth_img is None: return 0.0
        try:
            depth_val = self.depth_img[y, x]
            if np.issubdtype(self.depth_img.dtype, np.integer):
                return float(depth_val) / 1000.0  # mm to meters
            elif np.issubdtype(self.depth_img.dtype, np.floating):
                return float(depth_val)  # already in meters
            return 0.0
        except Exception as e:
            self.get_logger().warn(f"Get depth error: {e}")
            return 0.0

    def depth_sector_distances(self) -> Tuple[float, float, float]:
        """ì¢Œ/ì¤‘ì•™/ìš° ì„¹í„°ì˜ ìµœì†Œ ê±°ë¦¬ ê³„ì‚°"""
        if self.depth_img is None: return (float('inf'), float('inf'), float('inf'))
        cx = COLOR_W // 2
        y = DEPTH_SAMPLE_Y
        def sector(px_start, px_end):
            vals = [self.get_depth_at_point(px, y) for px in range(px_start, px_end)]
            vals = [v for v in vals if 0.1 < v < 20.0]
            return min(vals) if vals else float('inf')
        left = sector(max(0, cx - 3*DEPTH_SECTOR_WIDTH), max(0, cx - DEPTH_SECTOR_WIDTH))
        front = sector(max(0, cx - DEPTH_SECTOR_WIDTH), min(COLOR_W, cx + DEPTH_SECTOR_WIDTH))
        right = sector(min(COLOR_W-1, cx + DEPTH_SECTOR_WIDTH), min(COLOR_W, cx + 3*DEPTH_SECTOR_WIDTH))
        return left, front, right

    def auto_scan_for_gate(self):
        """(ìŠ¤ìº” ìš°ì„ ) ìë™ ì¢Œìš° ìŠ¤ìº”ìœ¼ë¡œ ê²Œì´íŠ¸ ì°¾ê¸°"""
        current_time = time.time()
        
        if (current_time - self.last_gate_seen_time > GATE_LOST_THRESHOLD):
            if (current_time - self.last_auto_scan_time < CONTINUOUS_SCAN_INTERVAL):
                return # ì¿¨íƒ€ì„
            
            self.last_auto_scan_time = current_time
            self.get_logger().info(f"ğŸ” [AUTO SCAN] ê²Œì´íŠ¸ #{self.gates_passed+1} ì°¾ê¸° - {self.scan_direction} ìŠ¤ìº”")
            
            if self.scan_direction == 'left':
                set_motor_state_named('left'); time.sleep(SCAN_TURN_TIME)
                self.scan_direction = 'right'
            else:
                set_motor_state_named('right'); time.sleep(SCAN_TURN_TIME)
                self.scan_direction = 'left'
            set_motor_state_named('stop'); time.sleep(0.2)

    def process_frame(self):
        """ë©”ì¸ í”„ë¡œì„¸ì‹± ë¡œì§"""
        if self.color_img is None or self.mission_complete: return
        
        color_img = self.color_img.copy()
        hsv = cv2.cvtColor(color_img, cv2.COLOR_BGR2HSV)

        # ìƒ‰ìƒ ê°ì§€
        mask_red = mask_for_color(hsv, 'RED')
        mask_green = mask_for_color(hsv, 'GREEN')
        mask_yellow = mask_for_color(hsv, 'YELLOW')

        red_bbs_raw = find_all_contours_with_size_filter(mask_red, MIN_CONTOUR_AREA_RED, MAX_CONTOUR_AREA_RED)
        green_bbs = find_all_contours_with_size_filter(mask_green, MIN_CONTOUR_AREA_GREEN, MAX_CONTOUR_AREA_GREEN)
        yellow_bb = find_largest_contour_with_size_filter(mask_yellow, MIN_CONTOUR_AREA_YELLOW, MAX_CONTOUR_AREA_YELLOW)

        # 'ì´ˆë¡ ìš°ì„ ' í•„í„° ì ìš©
        red_bbs, green_bbs = filter_overlapping_colors(red_bbs_raw, green_bbs)

        # ë””ë²„ê·¸: ë¶€í‘œ í‘œì‹œ
        for bb in red_bbs: cv2.rectangle(color_img, (bb[0], bb[1]), (bb[0]+bb[2], bb[1]+bb[3]), (0, 0, 255), 2)
        for bb in green_bbs: cv2.rectangle(color_img, (bb[0], bb[1]), (bb[0]+bb[2], bb[1]+bb[3]), (0, 255, 0), 2)

        # ë¯¸ì…˜ ë‹¨ê³„ í‘œì‹œ
        stage_text = f"Stage: {self.mission_stage} | Gates: {self.gates_passed}/{TOTAL_GATES}"
        cv2.putText(color_img, stage_text, (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ë¯¸ì…˜ ë‹¨ê³„ë³„ ì²˜ë¦¬
        if self.mission_stage == 'NAVIGATION':
            self.navigation_stage_process(red_bbs, green_bbs, yellow_bb, color_img)
        elif self.mission_stage == 'STATION_KEEPING':
            self.station_keeping_stage_process(yellow_bb, color_img)
        elif self.mission_stage == 'DOCKING':
            self.docking_stage_process(color_img)
        
        cv2.imshow("Phase1 View", color_img)
        cv2.waitKey(1)
    
    # --- â­ï¸ [ë¡œì§ ìˆ˜ì • 1] ìˆœì°¨ ê²Œì´íŠ¸ í†µê³¼ ë¡œì§ ì ìš© ---
    def navigation_stage_process(self, red_bbs, green_bbs, yellow_bb, color_img):
        """í•­ë¡œ ì¶”ì¢… ë‹¨ê³„ ì²˜ë¦¬ (ìˆœì°¨ ê²Œì´íŠ¸ ê¸°ì–µ ë¡œì§ í¬í•¨)"""
        
        # 1. (ëª©í‘œ ë‹¬ì„±) ëª¨ë“  ê²Œì´íŠ¸ í†µê³¼ ì‹œ ë…¸ë€ ë¶€í‘œ íƒìƒ‰
        if self.gates_passed >= TOTAL_GATES:
            if yellow_bb:
                self.get_logger().info(f"âœ… ëª¨ë“  {TOTAL_GATES}ê°œ ê²Œì´íŠ¸ í†µê³¼ ì™„ë£Œ!")
                self.get_logger().info("ğŸŸ¡ ìœ„ì¹˜ìœ ì§€ êµ¬ì—­ ì§„ì… - ë…¸ë€ë¶€í‘œ ê°ì§€")
                self.mission_stage = 'STATION_KEEPING'
                self.last_gate_seen_time = time.time()
                return
            else:
                cv2.putText(color_img, f"All {TOTAL_GATES} gates passed! Searching YELLOW...", 
                           (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                # ë…¸ë€ ë¶€í‘œ ì°¾ê¸° = ìŠ¤ìº” + ì•ˆì „ ì „ì§„ (Depth Follow)
                self.auto_scan_for_gate()
                self.depth_follow(color_img)
                return
        
        # 2. (ë™ì‹œ ê°ì§€) ê²Œì´íŠ¸ í•œ ìŒì„ ë™ì‹œì— ì°¾ì€ ê²½ìš° (Best Case)
        if red_bbs and green_bbs:
            self.last_gate_seen_time = time.time()
            self.gate_passing_state = 'APPROACHING' 
            self.seen_buoy_half = None # ìˆœì°¨ ê¸°ì–µ ë¦¬ì…‹
            
            self.get_logger().info(f"ğŸ”´ğŸŸ¢ ë™ì‹œ ê°ì§€: ğŸ”´ {len(red_bbs)}ê°œ, ğŸŸ¢ {len(green_bbs)}ê°œ")
            gate_pair = find_closest_gate_pair(red_bbs, green_bbs, color_img.shape[1])
            
            if gate_pair:
                red_bb, green_bb = gate_pair
                rx, ry, rw, rh = red_bb; gx, gy, gw, gh = green_bb
                red_cx, green_cx = rx + rw//2, gx + gw//2
                red_cy, green_cy = ry + rh//2, gy + gh//2
                gate_center_x, gate_center_y = (red_cx + green_cx)//2, (red_cy + green_cy)//2
                
                # ê²Œì´íŠ¸ ê°•ì¡° í‘œì‹œ
                cv2.rectangle(color_img, (rx, ry), (rx+rw, ry+rh), (0, 0, 255), 3)
                cv2.rectangle(color_img, (gx, gy), (gx+gw, gy+gh), (0, 255, 0), 3)
                cv2.line(color_img, (gate_center_x, 0), (gate_center_x, COLOR_H), (255, 255, 0), 2)
                cv2.circle(color_img, (gate_center_x, gate_center_y), 10, (255, 255, 0), -1)
                cv2.putText(color_img, f"GATE #{self.gates_passed+1}/{TOTAL_GATES}", (20, 40), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                
                # ê²Œì´íŠ¸ í†µê³¼ ë° ì¹´ìš´íŒ…ì€ manage_gate_passingì´ ë‹´ë‹¹
                self.manage_gate_passing((gate_center_x, gate_center_y), color_img)
            else:
                # ë¶€í‘œëŠ” ë³´ì´ë‚˜ ìœ íš¨í•œ ìˆ˜í‰ ê²Œì´íŠ¸ê°€ ì•„ë‹˜ -> ìŠ¤ìº”
                self.get_logger().info("ë¶€í‘œëŠ” ë³´ì´ë‚˜ ìœ íš¨í•œ (ì¢Œ/ìš°, ìˆ˜í‰) ê²Œì´íŠ¸ê°€ ì—†ìŒ -> ìŠ¤ìº”")
                cv2.putText(color_img, "Searching valid gate pair...", (20, 40), 
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                self.auto_scan_for_gate()
        
        # 3. (ë‹¨ë… ê°ì§€) í•œìª½ ë¶€í‘œë§Œ ì°¾ì€ ê²½ìš° (ìˆœì°¨ ê¸°ì–µ ë¡œì§)
        elif red_bbs or green_bbs:
            self.last_gate_seen_time = time.time()
            visible_color = 'RED' if red_bbs else 'GREEN'
            bb = red_bbs[0] if red_bbs else green_bbs[0]
            cx = bb[0] + bb[2]//2
            frame_cx = color_img.shape[1] // 2
            position = 'LEFT' if cx < frame_cx else 'RIGHT'
            current_seen = f"{visible_color}_{position}" # ì˜ˆ: "GREEN_LEFT"

            # 3a. ì²« ë²ˆì§¸ ì§ì„ ë³¸ ê²½ìš°
            if self.seen_buoy_half is None:
                # ìœ íš¨í•œ ì²« ì§ì€ (ì¢Œì¸¡ ì´ˆë¡) ë˜ëŠ” (ìš°ì¸¡ ë¹¨ê°•)
                if current_seen == 'GREEN_LEFT' or current_seen == 'RED_RIGHT':
                    self.seen_buoy_half = current_seen
                    self.last_seen_half_time = time.time()
                    self.get_logger().info(f"1ï¸âƒ£ ì²« ë²ˆì§¸ ë¶€í‘œ ({current_seen}) ë°œê²¬. ì§ì„ ì°¾ìŠµë‹ˆë‹¤.")
                    self.scan_for_pair(visible_color, cx, color_img)
                else:
                    # (ì˜ˆ: GREEN_RIGHT) ì˜ëª»ëœ ìœ„ì¹˜. ì§(RED_RIGHT)ì„ ì°¾ê¸° ìœ„í•´ ìŠ¤ìº”
                    self.get_logger().info(f"ì˜ëª»ëœ ìœ„ì¹˜ì˜ ë¶€í‘œ ({current_seen}) ë°œê²¬. ì§ì„ ì°¾ìŠµë‹ˆë‹¤.")
                    self.scan_for_pair(visible_color, cx, color_img)

            # 3b. ë‘ ë²ˆì§¸ ì§ì„ ë³¸ ê²½ìš° (ê¸°ì–µì´ ìˆëŠ” ìƒíƒœ)
            else:
                expected_pair = 'RED_RIGHT' if self.seen_buoy_half == 'GREEN_LEFT' else 'GREEN_LEFT'
                is_valid_pair = (current_seen == expected_pair)
                is_timeout = (time.time() - self.last_seen_half_time) > SEQUENTIAL_GATE_MEMORY_TIME

                if is_valid_pair and not is_timeout:
                    # â­ [ìˆœì°¨ í†µê³¼ ì„±ê³µ]
                    self.get_logger().info(f"2ï¸âƒ£ ìˆœì°¨ ê²Œì´íŠ¸ í†µê³¼ ì„±ê³µ! ({self.seen_buoy_half} -> {current_seen})")
                    self.gates_passed += 1
                    self.get_logger().info(f"âœ… ê²Œì´íŠ¸ #{self.gates_passed}/{TOTAL_GATES} í†µê³¼ ì™„ë£Œ!")
                    self.seen_buoy_half = None # ê¸°ì–µ ë¦¬ì…‹
                    self.gate_passing_state = 'PASSING' # í†µê³¼ ì¤‘ ìƒíƒœë¡œ ë³€ê²½
                    # ê²Œì´íŠ¸ í†µê³¼ë¥¼ ìœ„í•´ ì ì‹œ ì „ì§„
                    self.continuous_forward(color_img) 
                elif is_timeout:
                    # ê¸°ì–µ ì‹œê°„ ì´ˆê³¼
                    self.get_logger().info(f"â° ê¸°ì–µ ì‹œê°„ ì´ˆê³¼. ({self.seen_buoy_half}) ìŠìŒ.")
                    # ìƒˆë¡œ ë³¸ ë¶€í‘œë¥¼ ì²« ë²ˆì§¸ ì§ìœ¼ë¡œ ë‹¤ì‹œ ê¸°ì–µ
                    if current_seen == 'GREEN_LEFT' or current_seen == 'RED_RIGHT':
                        self.seen_buoy_half = current_seen
                        self.last_seen_half_time = time.time()
                        self.get_logger().info(f"1ï¸âƒ£ ({current_seen})ë¥¼ ìƒˆ ì²« ë²ˆì§¸ ë¶€í‘œë¡œ ê¸°ì–µ.")
                        self.scan_for_pair(visible_color, cx, color_img)
                    else:
                        self.seen_buoy_half = None # ì˜ëª»ëœ ìœ„ì¹˜ë¼ ê¸°ì–µ ë¦¬ì…‹
                        self.scan_for_pair(visible_color, cx, color_img)
                else:
                    # ì˜ëª»ëœ ì§ì„ ë§Œë‚¨ (ì˜ˆ: GREEN_LEFT -> RED_LEFT)
                    if current_seen != self.seen_buoy_half: # ê°™ì€ ë¶€í‘œë¥¼ ê³„ì† ë³´ëŠ”ê²Œ ì•„ë‹ˆë¼ë©´
                        self.get_logger().info(f"âŒ ì˜ëª»ëœ ì§. ({self.seen_buoy_half}) ì´í›„ ({current_seen}) ë°œê²¬. ë¬´ì‹œ.")
                    # ì§ì„ ê³„ì† ì°¾ê¸° ìœ„í•´ ì›ë˜ ìŠ¤ìº” ë°©í–¥ ìœ ì§€
                    original_visible_color = 'GREEN' if self.seen_buoy_half == 'GREEN_LEFT' else 'RED'
                    self.scan_for_pair(original_visible_color, 0, color_img) # cx=0 (ì‚¬ìš©ì•ˆí•¨)

        # 4. (ê°ì§€ ì‹¤íŒ¨) ì•„ë¬´ ë¶€í‘œë„ ëª» ë³¸ ê²½ìš°
        else:
            cv2.putText(color_img, f"Searching gate #{self.gates_passed+1}/{TOTAL_GATES}...", (20, 40), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

            # 4a. ìˆœì°¨ ê¸°ì–µì´ íƒ€ì„ì•„ì›ƒë¨
            if self.seen_buoy_half is not None and (time.time() - self.last_seen_half_time) > SEQUENTIAL_GATE_MEMORY_TIME:
                self.get_logger().info(f"â° ë¶€í‘œ ì—†ìŒ. ê¸°ì–µ({self.seen_buoy_half}) ë¦¬ì…‹.")
                self.seen_buoy_half = None

            # 4b. ê²Œì´íŠ¸ í†µê³¼ ì§í›„(PASSING)ì—ë§Œ ì ì‹œ ì „ì§„
            if self.gate_passing_state == 'PASSING' and (time.time() - self.last_gate_seen_time < 2.0):
                self.continuous_forward(color_img)
            else:
                # 4c. ê·¸ ì™¸ì—ëŠ” ê²Œì´íŠ¸ë¥¼ ìƒì–´ë²„ë¦° ê²ƒ -> ìŠ¤ìº” ìš°ì„ 
                self.gate_passing_state = 'SEARCHING' # ìƒíƒœ ì´ˆê¸°í™”
                self.auto_scan_for_gate()
    
    def station_keeping_stage_process(self, yellow_bb, color_img):
        """ìœ„ì¹˜ìœ ì§€ ë‹¨ê³„ ì²˜ë¦¬"""
        if yellow_bb:
            self.last_gate_seen_time = time.time() # ë…¸ë€ ë¶€í‘œë„ 'í‘œì‹'ìœ¼ë¡œ ê°„ì£¼
            self.get_logger().info("ğŸŸ¡ ë…¸ë€ë¶€í‘œ ìœ„ì¹˜ìœ ì§€ ì¤‘")
            x, y, w, h = yellow_bb
            cv2.rectangle(color_img, (x, y), (x+w, y+h), (0, 255, 255), 2)
            cv2.putText(color_img, "STATION KEEPING", (x, y-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            
            if self.approach_yellow_and_wait(yellow_bb, color_img):
                self.get_logger().info("âœ… ìœ„ì¹˜ìœ ì§€ ì™„ë£Œ â†’ ë„í‚¹ ë‹¨ê³„ë¡œ ì „í™˜")
                self.mission_stage = 'DOCKING'
        else:
            # ë…¸ë€ ë¶€í‘œë¥¼ ìƒì–´ë²„ë ¸ìœ¼ë©´ ìŠ¤ìº” + ì•ˆì „ ì „ì§„
            cv2.putText(color_img, "Searching for yellow buoy...", (20, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            self.auto_scan_for_gate()
            self.depth_follow(color_img)
    
    def docking_stage_process(self, color_img):
        """ë„í‚¹ êµ¬ì—­ ì´ë™ ë‹¨ê³„"""
        self.get_logger().info(f"ğŸš¢ ë„í‚¹ êµ¬ì—­ìœ¼ë¡œ {AFTER_YELLOW_FORWARD_TIME}ì´ˆ ì „ì§„")
        cv2.putText(color_img, "Moving to DOCK", (20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        set_motor_state_named('forward'); time.sleep(AFTER_YELLOW_FORWARD_TIME)
        set_motor_state_named('stop')
        
        self.get_logger().info("âœ… Phase1 ì™„ë£Œ")
        self.mission_complete = True
    
    def manage_gate_passing(self, gate_center: Tuple[int, int], frame: np.ndarray):
        """(ë™ì‹œ ê°ì§€ëœ) ê²Œì´íŠ¸ í†µê³¼ ìƒíƒœ ê´€ë¦¬ ë° ì¹´ìš´íŒ…"""
        gate_x, gate_y = gate_center
        frame_cx = frame.shape[1]//2
        
        # ê²Œì´íŠ¸ê°€ í™”ë©´ í•˜ë‹¨ì— ê°€ê¹Œì›Œì§€ë©´ í†µê³¼ ë° ì¹´ìš´íŠ¸
        if gate_y > COLOR_H * 0.7:  # í™”ë©´ í•˜ë‹¨ 70%
            if self.gate_passing_state != 'PASSING':
                self.get_logger().info(f"ğŸšª ê²Œì´íŠ¸ #{self.gates_passed+1} (ë™ì‹œ) í†µê³¼ ì‹œì‘")
                self.gate_passing_state = 'PASSING'
                self.gates_passed += 1 # í†µê³¼ ì‹œì‘ ì‹œì ì— ì¹´ìš´íŠ¸
                self.get_logger().info(f"âœ… ê²Œì´íŠ¸ #{self.gates_passed}/{TOTAL_GATES} í†µê³¼ ì™„ë£Œ!")
            
            # ì¤‘ì•™ ì •ë ¬í•˜ë©° í†µê³¼
            error = gate_x - frame_cx
            if abs(error) > GATE_CENTER_DEADZONE:
                if error > 0: set_motor_state_named('right'); time.sleep(TURN_SMALL_TIME * 0.3)
                else: set_motor_state_named('left'); time.sleep(TURN_SMALL_TIME * 0.3)
            
            set_motor_state_named('forward'); time.sleep(APPROACH_FORWARD_TIME * 1.5) 
            set_motor_state_named('stop')
            
        else:
            # ê²Œì´íŠ¸ ì ‘ê·¼ ì¤‘ - ì¤‘ì•™ ì •ë ¬
            self.gate_passing_state = 'APPROACHING'
            error = gate_x - frame_cx
            
            if abs(error) <= GATE_CENTER_DEADZONE:
                self.get_logger().info("âœ… ê²Œì´íŠ¸ ì¤‘ì•™ ì •ë ¬ ì™„ë£Œ â†’ ì „ì§„")
                set_motor_state_named('forward'); time.sleep(APPROACH_FORWARD_TIME)
            elif error > 0:
                self.get_logger().info(f"ê²Œì´íŠ¸ê°€ ìš°ì¸¡ì— {error}px â†’ ìš°íšŒì „")
                set_motor_state_named('right'); time.sleep(TURN_SMALL_TIME) 
            else:
                self.get_logger().info(f"ê²Œì´íŠ¸ê°€ ì¢Œì¸¡ì— {abs(error)}px â†’ ì¢ŒíšŒì „")
                set_motor_state_named('left'); time.sleep(TURN_SMALL_TIME)
            set_motor_state_named('stop')
    
    def continuous_forward(self, frame: np.ndarray):
        """ê²Œì´íŠ¸ í†µê³¼ ì§í›„(ìˆœì°¨/ë™ì‹œ) ë‹¤ìŒ ê²Œì´íŠ¸ íƒìƒ‰ì„ ìœ„í•œ ì „ì§„"""
        self.get_logger().info("ğŸš€ (PASSING) ê²Œì´íŠ¸ í†µê³¼ ì¤‘ - ì—°ì† ì „ì§„")
        
        # ì „ë°© ì•ˆì „ í™•ì¸ í›„ ì „ì§„
        left, front, right = self.depth_sector_distances()
        
        if front > DEPTH_SAFE_DISTANCE and front != float('inf'):
            set_motor_state_named('forward')
            time.sleep(FORWARD_SPEED_TIME * 2)
        else:
            self.get_logger().warn("! ê²Œì´íŠ¸ í†µê³¼ ì¤‘ ì¥ì• ë¬¼ ê°ì§€, íšŒí”¼")
            if left > right: set_motor_state_named('left'); time.sleep(TURN_SMALL_TIME * 0.5)
            else: set_motor_state_named('right'); time.sleep(TURN_SMALL_TIME * 0.5)
        
        set_motor_state_named('stop')
        
        # ê²Œì´íŠ¸ í†µê³¼ í›„ 'íƒìƒ‰' ìƒíƒœë¡œ ìë™ ë³µê·€ (2ì´ˆ í›„)
        if time.time() - self.last_gate_seen_time > 2.0:
            self.get_logger().info("...ì—°ì† ì „ì§„ ì™„ë£Œ, íƒìƒ‰ ëª¨ë“œë¡œ ë³µê·€")
            self.gate_passing_state = 'SEARCHING'

    def scan_for_pair(self, visible_color: str, cx: int, frame: np.ndarray):
        """í•œìª½ ë¶€í‘œë§Œ ë³´ì¼ ë•Œ ì§ ì°¾ê¸° ìœ„í•œ ìŠ¤ìº”"""
        current_time = time.time()
        if current_time - self.last_scan_time < 1.0: return # ì¿¨íƒ€ì„
        self.last_scan_time = current_time
        
        # ë³´ì´ëŠ” ë¶€í‘œì˜ ë°˜ëŒ€í¸ì„ ìŠ¤ìº”
        if visible_color == 'GREEN':
            self.get_logger().info("ğŸŸ¢ ì´ˆë¡ ê°ì§€ â†’ ìš°ì¸¡(ë¹¨ê°•) ìŠ¤ìº”")
            set_motor_state_named('right'); time.sleep(SCAN_TURN_TIME * 0.7)
        else: # RED
            self.get_logger().info("ğŸ”´ ë¹¨ê°• ê°ì§€ â†’ ì¢Œì¸¡(ì´ˆë¡) ìŠ¤ìº”")
            set_motor_state_named('left'); time.sleep(SCAN_TURN_TIME * 0.7)
        
        set_motor_state_named('stop')

    def depth_follow(self, frame: np.ndarray):
        """(ê²Œì´íŠ¸ íƒìƒ‰ ì‹¤íŒ¨ ì‹œ) ê¹Šì´ ê¸°ë°˜ íšŒí”¼/ì „ì§„"""
        left, front, right = self.depth_sector_distances()
        
        self.get_logger().info(f"[DEPTH] L:{left:.2f} / F:{front:.2f} / R:{right:.2f}")
        if front > DEPTH_SAFE_DISTANCE and front != float('inf'):
            self.get_logger().info("ì „ë°© ì•ˆì „ â†’ ì „ì§„ (Depth Follow)")
            set_motor_state_named('forward'); time.sleep(FORWARD_SPEED_TIME)
        elif left > right:
            self.get_logger().info("ì¢Œì¸¡ ê³µê°„ ì—¬ìœ  â†’ ì¢ŒíšŒì „ (Depth Follow)")
            set_motor_state_named('left'); time.sleep(TURN_SMALL_TIME)
        else:
            self.get_logger().info("ìš°ì¸¡ ê³µê°„ ì—¬ìœ  â†’ ìš°íšŒì „ (Depth Follow)")
            set_motor_state_named('right'); time.sleep(TURN_SMALL_TIME)
        set_motor_state_named('stop')
    
    def approach_yellow_and_wait(self, yellow_bb: Tuple[int, int, int, int], frame: np.ndarray) -> bool:
        """ë…¸ë€ë¶€í‘œ ì ‘ê·¼ ë° ì¼ì • ê±°ë¦¬ ë‚´ ì •ì§€ ëŒ€ê¸°"""
        x, y, w, h = yellow_bb
        cx, cy = x + w // 2, y + h // 2
        depth = self.get_depth_at_point(cx, cy)
        
        if depth == 0 or np.isnan(depth) or depth > 20.0:
            self.get_logger().info(f"[YELLOW] ê¹Šì´ ì •ë³´ ì—†ìŒ/ìœ íš¨í•˜ì§€ ì•ŠìŒ ({depth:.2f}m) â†’ ì •ì§€")
            set_motor_state_named('stop')
            return False
        
        self.get_logger().info(f"[YELLOW] ë…¸ë€ë¶€í‘œ ê±°ë¦¬: {depth:.2f}m")
        
        if depth > YELLOW_STOP_DISTANCE:
            # ê±°ë¦¬ê°€ ë©€ë©´, ì¤‘ì‹¬ìœ¼ë¡œ ì •ë ¬í•˜ë©° ì „ì§„
            frame_cx = frame.shape[1] // 2
            error = cx - frame_cx
            if abs(error) > GATE_CENTER_DEADZONE:
                if error > 0: set_motor_state_named('right'); time.sleep(TURN_SMALL_TIME)
                else: set_motor_state_named('left'); time.sleep(TURN_SMALL_TIME)
            else:
                set_motor_state_named('forward'); time.sleep(APPROACH_FORWARD_TIME)
            set_motor_state_named('stop')
            return False
        else:
            # ëª©í‘œ ê±°ë¦¬ ì´ë‚´ ë„ë‹¬
            self.get_logger().info("ğŸŸ¡ 5m ì´ë‚´ ë„ë‹¬ â†’ ì •ì§€ ë° 5ì´ˆ ëŒ€ê¸°")
            set_motor_state_named('stop')
            for i in range(int(YELLOW_WAIT_TIME), 0, -1):
                self.get_logger().info(f"â±ï¸  {i}ì´ˆ...")
                time.sleep(1)
            self.get_logger().info("âœ… 5ì´ˆ ëŒ€ê¸° ì™„ë£Œ!")
            return True

def main(args=None):
    rclpy.init(args=args)
    node = Phase1Navigator()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        if motor_controller:
            motor_controller.close()
        cv2.destroyAllWindows()
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()